{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 66653,
          "databundleVersionId": 7500999,
          "sourceType": "competition"
        },
        {
          "sourceId": 7518925,
          "sourceType": "datasetVersion",
          "datasetId": 4379849
        }
      ],
      "dockerImageVersionId": 30674,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9c8717de1d88486885ddac100ef4bb49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff38e9c6f7f54544ad6fd8a272dec14a",
              "IPY_MODEL_e15df6ef20a948d6a21a9237313fa555",
              "IPY_MODEL_018cdec142484aff853527234cf8ee7f"
            ],
            "layout": "IPY_MODEL_35fd6b0c2f3446129c7f9f4561192b01"
          }
        },
        "ff38e9c6f7f54544ad6fd8a272dec14a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_379205333dd5488380b59130f9151451",
            "placeholder": "​",
            "style": "IPY_MODEL_7c223089795c4c63b0396abc9b130da1",
            "value": "Map: 100%"
          }
        },
        "e15df6ef20a948d6a21a9237313fa555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_871150f8037f4683b7bf13358ac92e66",
            "max": 5987,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ba002a3ea794c96b2341b63ff08af02",
            "value": 5987
          }
        },
        "018cdec142484aff853527234cf8ee7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24cb036763404e369df1873420ea4ba0",
            "placeholder": "​",
            "style": "IPY_MODEL_5b2f84952978492e89bdea8065461b08",
            "value": " 5987/5987 [00:48&lt;00:00, 114.18 examples/s]"
          }
        },
        "35fd6b0c2f3446129c7f9f4561192b01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "379205333dd5488380b59130f9151451": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c223089795c4c63b0396abc9b130da1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "871150f8037f4683b7bf13358ac92e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba002a3ea794c96b2341b63ff08af02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "24cb036763404e369df1873420ea4ba0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b2f84952978492e89bdea8065461b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "078142239b734f539afc4d7c0eac5d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f1854a04b4b49babc47adf14f3b978e",
              "IPY_MODEL_0ab62af28d2d47c58ca290475370a90d",
              "IPY_MODEL_e71ac0ac17b240cf97b1c7773a9e31b5"
            ],
            "layout": "IPY_MODEL_df8a0849ea154e4d824dc1e353bec4a8"
          }
        },
        "3f1854a04b4b49babc47adf14f3b978e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec267f404aa241df92c7d8a20a7d252e",
            "placeholder": "​",
            "style": "IPY_MODEL_be8086ed1b5545459cc9835a39aa29fd",
            "value": "Map: 100%"
          }
        },
        "0ab62af28d2d47c58ca290475370a90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a09e15dcb994443cbfb4f9b6a7b9ce7a",
            "max": 1270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f7fd56903f047798ac9ee7e9bb8c37e",
            "value": 1270
          }
        },
        "e71ac0ac17b240cf97b1c7773a9e31b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e49f2ef4522b469d8dd5a1fa97c11a83",
            "placeholder": "​",
            "style": "IPY_MODEL_260a56c204a347c486e1b114c322c1da",
            "value": " 1270/1270 [00:10&lt;00:00, 122.26 examples/s]"
          }
        },
        "df8a0849ea154e4d824dc1e353bec4a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec267f404aa241df92c7d8a20a7d252e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8086ed1b5545459cc9835a39aa29fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a09e15dcb994443cbfb4f9b6a7b9ce7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f7fd56903f047798ac9ee7e9bb8c37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e49f2ef4522b469d8dd5a1fa97c11a83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260a56c204a347c486e1b114c322c1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "254c0c06be7444fd929f42aae6b44023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57f3e35429ff4a22a520bfe389ea3554",
              "IPY_MODEL_643074df549c453396a5500f1180fde1",
              "IPY_MODEL_f5266e672e714e0085473abf111b97c1"
            ],
            "layout": "IPY_MODEL_ed192917cc964efa88a2fc1b9bf3d1d6"
          }
        },
        "57f3e35429ff4a22a520bfe389ea3554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f2fd8452d5348b1b5299baa7305ea10",
            "placeholder": "​",
            "style": "IPY_MODEL_d057e3d5c143453b9899ba91656723f6",
            "value": "Map: 100%"
          }
        },
        "643074df549c453396a5500f1180fde1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_173ca4bc254d461a9f453430f50f89dd",
            "max": 1281,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_94cdc47a79e24e0582909eb9ec001168",
            "value": 1281
          }
        },
        "f5266e672e714e0085473abf111b97c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e47211ea8c88427c9a777ae47dd30e78",
            "placeholder": "​",
            "style": "IPY_MODEL_ee18186bcd514aec8bdf0e3a001341e8",
            "value": " 1281/1281 [00:10&lt;00:00, 121.61 examples/s]"
          }
        },
        "ed192917cc964efa88a2fc1b9bf3d1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f2fd8452d5348b1b5299baa7305ea10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d057e3d5c143453b9899ba91656723f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "173ca4bc254d461a9f453430f50f89dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94cdc47a79e24e0582909eb9ec001168": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e47211ea8c88427c9a777ae47dd30e78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee18186bcd514aec8bdf0e3a001341e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9fa80a7e9834d96b60156854f072931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_690fb50d85294534875851224e7c1698",
              "IPY_MODEL_5362b56fbb1a4d47b336be0305a91323",
              "IPY_MODEL_735e1a1504de4aff9a3d5af6a37ddb59"
            ],
            "layout": "IPY_MODEL_cc044dcf181e4a028a8d122501fe5c38"
          }
        },
        "690fb50d85294534875851224e7c1698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a353ca97357a4e2c82edfd1e62b2a071",
            "placeholder": "​",
            "style": "IPY_MODEL_0e199978a88d409d8de1c56d66e4c462",
            "value": "Map: 100%"
          }
        },
        "5362b56fbb1a4d47b336be0305a91323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27094111485e46ae860870da62da1c9d",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7574ebd2ed14e0091cc2c3e66c73802",
            "value": 10
          }
        },
        "735e1a1504de4aff9a3d5af6a37ddb59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ba5cefa566e45e3a0c7ba3225cf82a5",
            "placeholder": "​",
            "style": "IPY_MODEL_beb089b7dcdb493c9bf3388d7361ce6e",
            "value": " 10/10 [00:00&lt;00:00, 65.19 examples/s]"
          }
        },
        "cc044dcf181e4a028a8d122501fe5c38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a353ca97357a4e2c82edfd1e62b2a071": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e199978a88d409d8de1c56d66e4c462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27094111485e46ae860870da62da1c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7574ebd2ed14e0091cc2c3e66c73802": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ba5cefa566e45e3a0c7ba3225cf82a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb089b7dcdb493c9bf3388d7361ce6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Longformer Model for PII detection"
      ],
      "metadata": {
        "id": "ydzfMbL5ovoh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing required libararies"
      ],
      "metadata": {
        "id": "9B-mwE6-orHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFgI3ZSDrMbd",
        "outputId": "14adcbf9-ccdc-4c37-9233-b013465861c6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl (542 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.14.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "Successfully installed datasets-2.19.1 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 xxhash-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seqeval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jByL9RftWsM",
        "outputId": "5cd24d67-5372-4b8c-ccbe-8396ff01af94"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=ac6f431e1a13ec4c4de54b223b1c6272e4f254cdf2be438534f027509fca1bb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YihYLuRCvGiW",
        "outputId": "ea225cea-7598-450f-8100-e2fe5f9e2dca"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.30.1-py3-none-any.whl (302 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m276.5/302.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.2.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, accelerate\n",
            "Successfully installed accelerate-0.30.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required libraries"
      ],
      "metadata": {
        "id": "IUhzCW2fo0ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.simplefilter('ignore')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-05-12T02:10:49.710304Z",
          "iopub.execute_input": "2024-05-12T02:10:49.711425Z",
          "iopub.status.idle": "2024-05-12T02:10:49.716937Z",
          "shell.execute_reply.started": "2024-05-12T02:10:49.711384Z",
          "shell.execute_reply": "2024-05-12T02:10:49.715546Z"
        },
        "trusted": true,
        "id": "Z4PQ8OBjrATW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Workflow essentials\n",
        "import gc\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import argparse\n",
        "from itertools import chain\n",
        "from functools import partial\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datasets import Dataset, features, DatasetDict\n",
        "\n",
        "# Data preprocessing and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Model development\n",
        "from sklearn.metrics import f1_score\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoModelForTokenClassification\n",
        "from transformers import DataCollatorForTokenClassification"
      ],
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.status.busy": "2024-05-12T02:20:38.531609Z",
          "iopub.execute_input": "2024-05-12T02:20:38.532047Z",
          "iopub.status.idle": "2024-05-12T02:20:38.540330Z",
          "shell.execute_reply.started": "2024-05-12T02:20:38.532013Z",
          "shell.execute_reply": "2024-05-12T02:20:38.538558Z"
        },
        "trusted": true,
        "id": "EWw-UoPUrATX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define configuration class"
      ],
      "metadata": {
        "id": "y-iwRJJmpksB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CFG:\n",
        "    # Paths to datasets\n",
        "    comp_data = '/content/train.json'\n",
        "    ext_data = '/content/mixtral-8x7b-v1.json'\n",
        "    ext_data2 = '/content/PII_Detect_GPT3.5_Generated_data_v1.json'\n",
        "    # Model paths for loading and saving\n",
        "    # checkpoint = 'distilbert/distilbert-base-uncased'\n",
        "    # output_name = 'distilbert'\n",
        "    # output_dir = 'output'\n",
        "\n",
        "    # Data preprocessing\n",
        "    downsample = 0.29\n",
        "    max_len = 2048\n",
        "    workers = 4\n",
        "\n",
        "    # Model params\n",
        "    learning_rate = 5e-5\n",
        "    weight_decay = 0.01\n",
        "    warmup_ratio = 0.1\n",
        "    batch_size = 4\n",
        "    grad_steps = 2\n",
        "    log_steps = 10\n",
        "    epochs = 2\n",
        "\n",
        "    # Global seed\n",
        "    seed = 457"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:10:54.397350Z",
          "iopub.execute_input": "2024-05-12T02:10:54.397751Z",
          "iopub.status.idle": "2024-05-12T02:10:54.404861Z",
          "shell.execute_reply.started": "2024-05-12T02:10:54.397722Z",
          "shell.execute_reply": "2024-05-12T02:10:54.403431Z"
        },
        "trusted": true,
        "id": "C6qd533RrATX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def global_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:11:03.673331Z",
          "iopub.execute_input": "2024-05-12T02:11:03.673744Z",
          "iopub.status.idle": "2024-05-12T02:11:03.679394Z",
          "shell.execute_reply.started": "2024-05-12T02:11:03.673713Z",
          "shell.execute_reply": "2024-05-12T02:11:03.677892Z"
        },
        "trusted": true,
        "id": "B1ed2BDhrATX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility across multiple libraries\n",
        "global_seed(CFG.seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:11:00.454955Z",
          "iopub.execute_input": "2024-05-12T02:11:00.455848Z",
          "iopub.status.idle": "2024-05-12T02:11:00.461154Z",
          "shell.execute_reply.started": "2024-05-12T02:11:00.455793Z",
          "shell.execute_reply": "2024-05-12T02:11:00.459850Z"
        },
        "trusted": true,
        "id": "YNSwjBBBrATY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:11:06.131755Z",
          "iopub.execute_input": "2024-05-12T02:11:06.132173Z",
          "iopub.status.idle": "2024-05-12T02:11:06.771409Z",
          "shell.execute_reply.started": "2024-05-12T02:11:06.132142Z",
          "shell.execute_reply": "2024-05-12T02:11:06.769944Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h2PjLUVQrATY",
        "outputId": "0953f01f-8315-41f4-fcb3-328683d3214c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing steps(merging and undersampling)"
      ],
      "metadata": {
        "id": "coFZhFdQpuW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DataPreprocessor:\n",
        "    def load_clean_concat_data(self, path1, path2, path3, downsample, max_length, seed):\n",
        "        # Load JSON data as pandas DataFrames\n",
        "        df1 = pd.read_json(path1)\n",
        "        df2 = pd.read_json(path2)\n",
        "        df3 = pd.read_json(path3)\n",
        "\n",
        "        # Concatenate both DataFrames\n",
        "        concat_df1 = pd.concat([df1, df2], ignore_index=True)\n",
        "        concat_df = pd.concat([concat_df1, df3], ignore_index=True)\n",
        "\n",
        "        # Display the shape of the DataFrame before filtering\n",
        "        print(f\"Shape of DataFrame before filtering: {concat_df.shape}\")\n",
        "\n",
        "        # Identify rows with positive PII labels\n",
        "        concat_df['has_positive_PII'] = concat_df['labels'].apply(lambda x: any(label.startswith('B-') or label.startswith('I-') for label in x))\n",
        "\n",
        "        # Downsample rows without positive PII labels\n",
        "        df_without_positive_PII = concat_df[~concat_df['has_positive_PII']].sample(frac=downsample, random_state=seed)\n",
        "\n",
        "        # Concatenate rows with positive PII labels and downsampled rows without positive PII labels\n",
        "        concat_df = pd.concat([concat_df[concat_df['has_positive_PII']], df_without_positive_PII])\n",
        "\n",
        "        # Drop the auxiliary column used for filtering\n",
        "        concat_df.drop(columns=['has_positive_PII'], inplace=True)\n",
        "\n",
        "        # Display the shape of the DataFrame after filtering\n",
        "        print(f\"Shape of DataFrame after filtering: {concat_df.shape}\")\n",
        "        display(concat_df.head())\n",
        "\n",
        "        # Count essays with lengths smaller and longer than max_length\n",
        "        smaller_than_max_len = concat_df[concat_df['tokens'].apply(len) <= max_length]['tokens'].count()\n",
        "        longer_than_max_len = concat_df[concat_df['tokens'].apply(len) > max_length]['tokens'].count()\n",
        "\n",
        "        # Calculate the percentage of essays with length longer than max_length\n",
        "        total_essays = concat_df['tokens'].count()\n",
        "        percentage_longer_than_max = (longer_than_max_len / total_essays) * 100\n",
        "\n",
        "        # Create a DataFrame to display counts\n",
        "        counts_df = pd.DataFrame({\n",
        "            'Token Length': [f'Shorter than {max_length}', f'Longer than {max_length}'],\n",
        "            'Count': [smaller_than_max_len, longer_than_max_len]\n",
        "        })\n",
        "\n",
        "        # Display counts\n",
        "        display(counts_df)\n",
        "\n",
        "        # Print the percentage of essays with length longer than max_length\n",
        "        print(f\"Percentage of essays longer than {max_length} tokens: {percentage_longer_than_max:.2f}%\")\n",
        "\n",
        "        # Convert DataFrame back to JSON format\n",
        "#         json_data = concat_df.to_json(orient='records')\n",
        "\n",
        "#         # Convert JSON data back to list of dictionaries\n",
        "#         data = json.loads(json_data)\n",
        "\n",
        "        # Return data\n",
        "        return concat_df\n",
        "\n",
        "    def tokenize(self, example, tokenizer, label2id, max_length):\n",
        "        # Initialize empty lists to store tokens and corresponding labels\n",
        "        text, labels = [], []\n",
        "\n",
        "        # Iterate over each token, label, and whitespace indicator in the example\n",
        "        for token, label, whitespace in zip(example[\"tokens\"], example[\"provided_labels\"], example[\"trailing_whitespace\"]):\n",
        "            text.append(token)\n",
        "            labels.extend([label] * len(token))  # Extend labels for each token\n",
        "\n",
        "            # Append whitespace if present after the token\n",
        "            if whitespace:\n",
        "                text.append(\" \")\n",
        "                labels.append(\"O\")  # Add 'O' label for whitespace\n",
        "\n",
        "        # Reconstruct the text from tokens\n",
        "        text = \"\".join(text)\n",
        "\n",
        "        # Tokenize the text\n",
        "        tokenized = tokenizer(text,\n",
        "                              return_offsets_mapping=True,\n",
        "                              truncation=True,\n",
        "                              max_length=max_length)\n",
        "\n",
        "        # Initialize list to store labels assigned to each token\n",
        "        token_labels = []\n",
        "\n",
        "        # Iterate over token offset mappings\n",
        "        for start_idx, end_idx in tokenized.offset_mapping:\n",
        "            # Handle special case of CLS token\n",
        "            if start_idx == 0 and end_idx == 0:\n",
        "                token_labels.append(label2id[\"O\"])\n",
        "                continue\n",
        "\n",
        "            # Adjust start index if token starts with whitespace\n",
        "            if text[start_idx].isspace():\n",
        "                start_idx += 1\n",
        "\n",
        "            # Assign label ID to token based on start index\n",
        "            token_labels.append(label2id[labels[start_idx]])\n",
        "\n",
        "        # Calculate length of tokenized input sequence\n",
        "        length = len(tokenized.input_ids)\n",
        "\n",
        "        # Construct tokenized data dictionary\n",
        "        tokenized_data = {\n",
        "            \"input_ids\": tokenized.input_ids,\n",
        "            \"attention_mask\": tokenized.attention_mask,\n",
        "            \"labels\": token_labels,\n",
        "            \"length\": length\n",
        "        }\n",
        "\n",
        "        return tokenized_data\n",
        "\n",
        "# Initialize the DataPreprocessor\n",
        "dp = DataPreprocessor()"
      ],
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.status.busy": "2024-05-12T02:11:12.903098Z",
          "iopub.execute_input": "2024-05-12T02:11:12.903513Z",
          "iopub.status.idle": "2024-05-12T02:11:12.919780Z",
          "shell.execute_reply.started": "2024-05-12T02:11:12.903477Z",
          "shell.execute_reply": "2024-05-12T02:11:12.918729Z"
        },
        "trusted": true,
        "id": "EZLljwetrATY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# sample data - sequence length = 2048 for tokenizer and model"
      ],
      "metadata": {
        "id": "KnXCED9Sp4bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = dp.load_clean_concat_data(CFG.comp_data, CFG.ext_data, CFG.ext_data2, CFG.downsample, CFG.max_len, CFG.seed)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:11:22.644004Z",
          "iopub.execute_input": "2024-05-12T02:11:22.644975Z",
          "iopub.status.idle": "2024-05-12T02:11:26.028099Z",
          "shell.execute_reply.started": "2024-05-12T02:11:22.644940Z",
          "shell.execute_reply": "2024-05-12T02:11:26.026864Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "W9h-2H9GrATZ",
        "outputId": "b8e305c1-c43b-457d-ffcb-fea88606e052"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of DataFrame before filtering: (17443, 5)\n",
            "Shape of DataFrame after filtering: (8538, 5)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  document                                          full_text  \\\n",
              "0        7  Design Thinking for innovation reflexion-Avril...   \n",
              "1       10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
              "2       16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
              "3       20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
              "4       56  Assignment:  Visualization Reflection  Submitt...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [Design, Thinking, for, innovation, reflexion,...   \n",
              "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
              "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
              "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
              "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
              "\n",
              "                                 trailing_whitespace  \\\n",
              "0  [True, True, True, True, False, False, True, F...   \n",
              "1  [True, False, False, True, True, False, False,...   \n",
              "2  [True, False, False, True, True, False, False,...   \n",
              "3  [True, True, True, False, False, True, False, ...   \n",
              "4  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                              labels  \n",
              "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...  \n",
              "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...  \n",
              "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...  \n",
              "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...  \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ead91c67-b394-4814-af89-c2527e292882\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>full_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>trailing_whitespace</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
              "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
              "      <td>[True, True, True, True, False, False, True, F...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
              "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
              "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
              "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
              "      <td>[True, True, True, False, False, True, False, ...</td>\n",
              "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
              "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ead91c67-b394-4814-af89-c2527e292882')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ead91c67-b394-4814-af89-c2527e292882 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ead91c67-b394-4814-af89-c2527e292882');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-79240008-770d-465f-aeb9-7b5dcfae3d15\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-79240008-770d-465f-aeb9-7b5dcfae3d15')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-79240008-770d-465f-aeb9-7b5dcfae3d15 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data = dp\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 7,\n        \"max\": 56,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          10,\n          56,\n          16\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Diego Estrada\\n\\nDesign Thinking Assignment\\n\\nVisualization Tool\\n\\nChallenge & Selection\\n\\nThe elderly were having a hard time adapting to the changes we brought in our bank. As  a result of a poorly implemented linear solution, a more customer centric approach was  needed.\\n\\nAfter learning about design thinking in this course, we decided to apply it to solve this  problem. The visualization tool allowed the team to create a dynamic presentation using  diagrams, figures and drawings on the go that really resonated among the stakeholders.  Previous to this change, none of our solutions seemed to be adequate for them, but the  new implementation created a different type of connection with them that helped them  understand the problem in the way the team and I did.\\n\\nApplication\\n\\nThe process starts in the prep time. The team uses a series of tools and software to  develop a presentation using the surveys gathered during research and the solutions we  created during the process. The use of graphs to quickly show statistics in a fully visual  way, rather than verbally was a game changer.\\n\\nAfter having a presentation prepared, the team hands an activity to the stakeholders,  where the solutions discussed previously appear. Nonetheless, the solutions need more  work to them. After this. The stakeholders are asked to help complete the solutions  while the team and I create diagrams on a blackboard to represent how their  suggestions would impact on this specific problem.\\n\\nThe use of a group activity strengthens the bond between the company and their  investors. It makes them feel like they take part and help solve the problems as well as  show how customer centric the solutions are. Every complaint and suggestion from  customers are read and evaluated using the graph shown in the course (Involving: can  we do it? Can we afford it? \\u2026). The finalization of this activity leaves the team and the  stakeholders on the same page. It allows them to completely understand and feel part  of the solution and also gives them the chance to ask better questions, which eases the  work of the team.\\n\\nInsight & Approach\\n\\nThe use of this method created a new workflow in the Design Team. It increased the  productivity and the success rate as well as the customer/stakeholders satisfaction. The  use of the visualization tool created an engaged group of people who work together to\\n\\nDiego Estrada\\n\\nfind a solution based on their customer satisfaction. This solution is later revised and  tweaked with the help of the stakeholders who are deeply involved in the process.\\n\\nPresentations, graphics, and activities have added a huge increase in satisfaction. As a  company we also learnt that engaging different areas can be difficult because of the  varying levels of understanding, but when paired with the adequate process things just  flow.\\n\\n(This story is fictional and was created for solving the assignment)\\n\\n\",\n          \"Assignment:\\u00a0 Visualization\\u00a0Reflection\\u00a0 Submitted\\u00a0by:\\u00a0Nadine Born\\u00a0 Course:\\u00a0 Design\\u00a0Thinking\\u00a0for\\u00a0Innovation\\u00a0 \\u00a0 Trail\\u00a0Challenge:\\u00a0To\\u00a0Build\\u00a0or\\u00a0Not\\u00a0to\\u00a0Build\\u00a0 \\u00a0 An\\u00a0environmental\\u00a0charity\\u00a0wanted\\u00a0to\\u00a0conduct\\u00a0a\\u00a0fundraising\\u00a0campaign\\u00a0to\\u00a0raise\\u00a0$4\\u00a0million\\u00a0to\\u00a0build\\u00a0a\\u00a0 public\\u00a0path\\u00a0in\\u00a0a\\u00a0busy\\u00a0tourist\\u00a0area\\u00a0of\\u00a0a\\u00a0small\\u00a0town\\u00a0in\\u00a0British\\u00a0Columbia,\\u00a0Canada.\\u00a0They\\u00a0had\\u00a0been\\u00a0gifted\\u00a0a\\u00a0 large\\u00a0piece\\u00a0of\\u00a0land\\u00a0by\\u00a0a\\u00a0local\\u00a0landowner,\\u00a0which\\u00a0was\\u00a0a\\u00a0substantial\\u00a0gift\\u00a0and\\u00a0prevented\\u00a0them\\u00a0from\\u00a0 needing\\u00a0to\\u00a0purchase\\u00a0the\\u00a0land,\\u00a0however,\\u00a0they\\u00a0still\\u00a0needed\\u00a0to\\u00a0raise\\u00a0a\\u00a0large\\u00a0amount\\u00a0of\\u00a0money\\u00a0in\\u00a0order\\u00a0to\\u00a0 pay\\u00a0for\\u00a0the\\u00a0supplies\\u00a0and\\u00a0labor\\u00a0to\\u00a0build\\u00a0the\\u00a0trail.\\u00a0\\u00a0 \\u00a0 Even\\u00a0though\\u00a0the\\u00a0local\\u00a0community\\u00a0appeared\\u00a0to\\u00a0be\\u00a0supportive\\u00a0of\\u00a0the\\u00a0trail,\\u00a0they\\u00a0could\\u00a0not\\u00a0provide\\u00a0 enough\\u00a0money\\u00a0from\\u00a0private\\u00a0donations\\u00a0to\\u00a0build\\u00a0it.\\u00a0If\\u00a0the\\u00a0summer\\u00a0vacation\\u00a0property\\u00a0owners\\u00a0did\\u00a0not\\u00a0 provide\\u00a0some\\u00a0funding,\\u00a0then\\u00a0there\\u00a0was\\u00a0a\\u00a0strong\\u00a0possibility\\u00a0that\\u00a0they\\u00a0would\\u00a0not\\u00a0raise\\u00a0enough\\u00a0money\\u00a0to\\u00a0 complete\\u00a0the\\u00a0trail.\\u00a0The\\u00a0charity\\u00a0did\\u00a0not\\u00a0know\\u00a0if\\u00a0the\\u00a0community\\u00a0as\\u00a0a\\u00a0whole\\u00a0would\\u00a0support\\u00a0the\\u00a0project\\u00a0 and\\u00a0needed\\u00a0to\\u00a0conduct\\u00a0testing\\u00a0with\\u00a0key\\u00a0influencers\\u00a0and\\u00a0potential\\u00a0donors\\u00a0to\\u00a0gauge\\u00a0their\\u00a0interest.\\u00a0 Building\\u00a0the\\u00a0trail\\u00a0without\\u00a0testing\\u00a0the\\u00a0support\\u00a0first\\u00a0was\\u00a0too\\u00a0risky\\u00a0because\\u00a0the\\u00a0charity\\u00a0did\\u00a0not\\u00a0have\\u00a0 enough\\u00a0money\\u00a0in\\u00a0reserve\\u00a0to\\u00a0cover\\u00a0the\\u00a0cost\\u00a0of\\u00a0the\\u00a0trail\\u00a0if\\u00a0the\\u00a0fundraising\\u00a0efforts\\u00a0were\\u00a0not\\u00a0successful.\\u00a0\\u00a0 \\u00a0 Tool\\u00a0Selection:\\u00a0Visualization\\u00a0 \\u00a0 Visualization\\u00a0is\\u00a0the\\u00a0process\\u00a0of\\u00a0\\u201cassembling\\u00a0scattered\\u00a0ideas\\u00a0into\\u00a0a\\u00a0compelling\\u00a0story\\u00a0that\\u00a0can\\u00a0generate\\u00a0 vivid\\u00a0mental\\u00a0images\\u201d\\u00a0(Designing\\u00a0for\\u00a0Growth,\\u00a0p49).\\u00a0\\u00a0As\\u00a0the\\u00a0consultant\\u00a0for\\u00a0the\\u00a0study,\\u00a0I\\u00a0chose\\u00a0 visualization\\u00a0because\\u00a0the\\u00a0charity\\u00a0had\\u00a0a\\u00a0firm\\u00a0concept\\u00a0of\\u00a0why\\u00a0they\\u00a0needed\\u00a0the\\u00a0trail,\\u00a0how\\u00a0it\\u00a0would\\u00a0 benefit\\u00a0the\\u00a0town,\\u00a0and\\u00a0how\\u00a0much\\u00a0it\\u00a0would\\u00a0cost\\u00a0but\\u00a0needed\\u00a0a\\u00a0persuasive\\u00a0way\\u00a0to\\u00a0tie\\u00a0it\\u00a0all\\u00a0together.\\u00a0The\\u00a0 business\\u00a0case\\u00a0for\\u00a0the\\u00a0project\\u00a0was\\u00a0strong\\u00a0but\\u00a0without\\u00a0a\\u00a0tool\\u00a0to\\u00a0help\\u00a0them\\u00a0illustrate\\u00a0how\\u00a0the\\u00a0trail\\u00a0would\\u00a0 positively\\u00a0impact\\u00a0the\\u00a0residents,\\u00a0there\\u00a0was\\u00a0little\\u00a0chance\\u00a0people\\u00a0would\\u00a0donate\\u00a0enough\\u00a0to\\u00a0meet\\u00a0the\\u00a0 budget.\\u00a0We\\u00a0needed\\u00a0a\\u00a0tool\\u00a0that\\u00a0provided\\u00a0a\\u00a0\\u201chead\\u00a0and\\u00a0heart\\u201d\\u00a0message\\u00a0to\\u00a0convince\\u00a0people\\u00a0to\\u00a0support\\u00a0 the\\u00a0project.\\u00a0Visualization\\u00a0provided\\u00a0the\\u00a0perfect\\u00a0combination\\u00a0of\\u00a0key\\u00a0messaging,\\u00a0beautiful\\u00a0photography,\\u00a0 architectural\\u00a0renderings,\\u00a0safety\\u00a0data,\\u00a0and\\u00a0budget\\u00a0criteria\\u00a0to\\u00a0create\\u00a0the\\u00a0vision\\u00a0for\\u00a0the\\u00a0project\\u00a0in\\u00a0an\\u00a0 easy\\u2010to\\u2010read\\u00a0document\\u00a0that\\u00a0was\\u00a0only\\u00a0four\\u00a0pages\\u00a0in\\u00a0length.\\u00a0Visualization\\u00a0allowed\\u00a0us\\u00a0to\\u00a0describe\\u00a0the\\u00a0 urgent\\u00a0and\\u00a0compelling\\u00a0need\\u00a0for\\u00a0the\\u00a0trail\\u00a0in\\u00a0a\\u00a0succinct\\u00a0and\\u00a0tangible\\u00a0way.\\u00a0\\u00a0 \\u00a0 Application\\u00a0 \\u00a0 Once\\u00a0we\\u00a0drafted\\u00a0the\\u00a0vision\\u00a0document,\\u00a0we\\u00a0worked\\u00a0with\\u00a0the\\u00a0charity\\u00a0to\\u00a0identify\\u00a0a\\u00a0list\\u00a0of\\u00a0people\\u00a0whose\\u00a0 opinion\\u00a0would\\u00a0be\\u00a0important\\u00a0to\\u00a0the\\u00a0success\\u00a0(or\\u00a0failure)\\u00a0of\\u00a0the\\u00a0fundraising\\u00a0campaign.\\u00a0The\\u00a0list\\u00a0included\\u00a0 past\\u00a0and\\u00a0potential\\u00a0donors,\\u00a0key\\u00a0influencers\\u00a0in\\u00a0the\\u00a0community\\u00a0such\\u00a0as\\u00a0large\\u00a0landowners\\u00a0and\\u00a0business\\u00a0 owners,\\u00a0affluent\\u00a0summer\\u2010only\\u00a0residents,\\u00a0and\\u00a0elected\\u00a0officials.\\u00a0We\\u00a0requested\\u00a0one\\u2010hour\\u00a0meetings\\u00a0with\\u00a0 all\\u00a0of\\u00a0the\\u00a0people\\u00a0on\\u00a0the\\u00a0list.\\u00a0If\\u00a0people\\u00a0did\\u00a0not\\u00a0want\\u00a0to\\u00a0meet\\u00a0with\\u00a0us\\u00a0in\\u00a0person,\\u00a0which\\u00a0was\\u00a0often\\u00a0the\\n\\ncase\\u00a0with\\u00a0the\\u00a0part\\u2010time\\u00a0residents,\\u00a0we\\u00a0offered\\u00a0to\\u00a0conduct\\u00a0the\\u00a0meetings\\u00a0by\\u00a0phone.\\u00a0When\\u00a0someone\\u00a0 agreed\\u00a0to\\u00a0meet\\u00a0with\\u00a0us,\\u00a0we\\u00a0emailed\\u00a0them\\u00a0the\\u00a0vision\\u00a0document\\u00a0so\\u00a0they\\u00a0could\\u00a0read\\u00a0it\\u00a0in\\u00a0advance\\u00a0and\\u00a0 prepare\\u00a0their\\u00a0questions.\\u00a0This\\u00a0created\\u00a0a\\u00a0good\\u00a0environment\\u00a0for\\u00a0an\\u00a0informed\\u00a0and\\u00a0candid\\u00a0dialogue.\\u00a0 \\u00a0 While\\u00a0the\\u00a0scheduling\\u00a0of\\u00a0the\\u00a0interviews\\u00a0was\\u00a0in\\u00a0progress,\\u00a0we\\u00a0designed\\u00a0a\\u00a0questionnaire\\u00a0to\\u00a0guide\\u00a0our\\u00a0 discussions.\\u00a0Consistently\\u00a0using\\u00a0the\\u00a0questionnaire\\u00a0ensured\\u00a0that\\u00a0we\\u00a0covered\\u00a0the\\u00a0same\\u00a0questions\\u00a0with\\u00a0all\\u00a0 the\\u00a0interviewees.\\u00a0The\\u00a0goal\\u00a0was\\u00a0to\\u00a0speak\\u00a0with\\u00a020\\u00a0\\u2013\\u00a025\\u00a0key\\u00a0influencers\\u00a0in\\u00a0the\\u00a0community\\u00a0and\\u00a0gauge\\u00a0 their\\u00a0interest\\u00a0in,\\u00a0or\\u00a0opposition\\u00a0to,\\u00a0supporting\\u00a0the\\u00a0fundraising\\u00a0efforts\\u00a0for\\u00a0the\\u00a0trail\\u00a0as\\u00a0either\\u00a0donors\\u00a0or\\u00a0 campaign\\u00a0volunteers\\u00a0or\\u00a0both.\\u00a0We\\u00a0successfully\\u00a0met\\u00a0with\\u00a024\\u00a0interviewees\\u00a0and\\u00a0compiled\\u00a0the\\u00a0feedback\\u00a0 into\\u00a0a\\u00a0summary\\u00a0report\\u00a0along\\u00a0with\\u00a0recommendations\\u00a0for\\u00a0the\\u00a0charity.\\u00a0The\\u00a0entire\\u00a0process\\u00a0took\\u00a0three\\u00a0 months.\\u00a0 \\u00a0 Insight\\u00a0 \\u00a0 Fundraising\\u00a0and\\u00a0design\\u00a0thinking\\u00a0both\\u00a0require\\u00a0a\\u00a0willingness\\u00a0to\\u00a0adapt\\u00a0and\\u00a0fail\\u00a0fast.\\u00a0Good\\u00a0fundraisers\\u00a0are\\u00a0 responsive\\u00a0to\\u00a0their\\u00a0donors\\u00a0and\\u00a0design\\u00a0thinking\\u00a0serves\\u00a0as\\u00a0the\\u00a0perfect\\u00a0platform\\u00a0to\\u00a0plan\\u00a0and\\u00a0launch\\u00a0new\\u00a0 fundraising\\u00a0initiatives;\\u00a0it\\u00a0is\\u00a0an\\u00a0ideal\\u00a0methodology\\u00a0for\\u00a0solving\\u00a0complex\\u00a0philanthropic\\u00a0issues.\\u00a0We\\u00a0are\\u00a0not\\u00a0 formally\\u00a0taught\\u00a0design\\u00a0thinking\\u00a0models\\u00a0in\\u00a0fundraising\\u00a0classes\\u00a0but\\u00a0they\\u00a0should\\u00a0be\\u00a0added\\u00a0to\\u00a0the\\u00a0 curriculum.\\u00a0\\u00a0 \\u00a0 Although\\u00a0it\\u00a0is\\u00a0not\\u00a0explicitly\\u00a0stated\\u00a0in\\u00a0the\\u00a0course\\u00a0videos,\\u00a0it\\u00a0occurred\\u00a0to\\u00a0me\\u00a0that\\u00a0both\\u00a0fundraising\\u00a0and\\u00a0 design\\u00a0thinking\\u00a0are\\u00a0rooted\\u00a0in\\u00a0communication\\u00a0and\\u00a0relationships\\u00a0and\\u00a0both\\u00a0are\\u00a0iterative\\u00a0processes\\u00a0based\\u00a0 on\\u00a0testing\\u00a0and\\u00a0investigation.\\u00a0The\\u00a0elusive\\u00a0synergy\\u00a0between\\u00a0art\\u00a0and\\u00a0science\\u00a0is\\u00a0as\\u00a0beautifully\\u00a0illustrated\\u00a0 by\\u00a0design\\u00a0thinking\\u00a0as\\u00a0it\\u00a0is\\u00a0as\\u00a0inherent\\u00a0in\\u00a0daily\\u00a0fundraising\\u00a0practice.\\u00a0\\u00a0\\u00a0 \\u00a0 Improvements\\u00a0for\\u00a0Next\\u00a0Time\\u00a0 \\u00a0 Visualization\\u00a0was\\u00a0an\\u00a0effective\\u00a0tool\\u00a0in\\u00a0this\\u00a0circumstance\\u00a0and\\u00a0I\\u00a0would\\u00a0use\\u00a0it\\u00a0again\\u00a0in\\u00a0a\\u00a0similar\\u00a0situation.\\u00a0 However,\\u00a0it\\u00a0would\\u00a0also\\u00a0be\\u00a0enlightening\\u00a0to\\u00a0create\\u00a0a\\u00a0journey\\u00a0map\\u00a0with\\u00a0a\\u00a0wide\\u00a0spectrum\\u00a0of\\u00a0people\\u00a0from\\u00a0 the\\u00a0town\\u00a0because\\u00a0there\\u00a0were\\u00a0many\\u00a0assumptions\\u00a0made\\u00a0during\\u00a0the\\u00a0visualization\\u00a0process\\u00a0about\\u00a0how\\u00a0the\\u00a0 trail\\u00a0would\\u00a0be\\u00a0used\\u00a0and\\u00a0what\\u00a0benefits\\u00a0would\\u00a0be\\u00a0desired\\u00a0by\\u00a0the\\u00a0tourists,\\u00a0local\\u00a0public,\\u00a0and\\u00a0sponsors.\\u00a0 Journey\\u00a0mapping\\u00a0would\\u00a0have\\u00a0confirmed\\u00a0the\\u00a0validity\\u00a0of\\u00a0those\\u00a0assumptions\\u00a0and\\u00a0supplemented\\u00a0the\\u00a0data\\u00a0 gathered\\u00a0during\\u00a0the\\u00a0interviews.\\u00a0\\u00a0 \\u00a0 The\\u00a0other\\u00a0tool\\u00a0that\\u00a0I\\u00a0would\\u00a0use\\u00a0next\\u00a0time\\u00a0in\\u00a0conjunction\\u00a0with\\u00a0visualization\\u00a0is\\u00a0storytelling.\\u00a0I\\u00a0would\\u00a0take\\u00a0 someone\\u2019s\\u00a0first\\u00a0hand\\u00a0account\\u00a0of\\u00a0the\\u00a0situation\\u00a0and\\u00a0create\\u00a0a\\u00a0short\\u00a0video\\u00a0to\\u00a0showcase\\u00a0the\\u00a0urgency\\u00a0of\\u00a0the\\u00a0 project\\u00a0or\\u00a0program\\u00a0from\\u00a0his/her\\u00a0perspective.\\u00a0A\\u00a0link\\u00a0to\\u00a0the\\u00a0video\\u00a0would\\u00a0be\\u00a0included\\u00a0in\\u00a0the\\u00a0email\\u00a0about\\u00a0 the\\u00a0interview\\u00a0along\\u00a0with\\u00a0a\\u00a0PDF\\u00a0of\\u00a0the\\u00a0vision\\u00a0document.\\u00a0I\\u00a0think\\u00a0this\\u00a0would\\u00a0provide\\u00a0a\\u00a0holistic\\u00a0micro\\u00a0and\\u00a0 macro\\u00a0perspective\\u00a0to\\u00a0the\\u00a0exercise\\u00a0and\\u00a0spark\\u00a0some\\u00a0interesting\\u00a0conversations\\u00a0in\\u00a0the\\u00a0interviews.\\n\\n\",\n          \"Reporting process\\n\\nby Gilberto Gamboa\\n\\nChallenge\\n\\nI received a promotion of being the Regional Controller, along with my actual position of\\n\\nCountry CFO. The main responsibility of this new position was to weekly report the results\\n\\nfor the week and estimate the final results of the month of 4 countries and consolidated\\n\\nthose.\\n\\nWhen I was receiving the position, I went to visit my colleague, former Regional Controller,\\n\\nwho was promoted to Country CEO and now had interest conflicts of being the controller.\\n\\nThe process to consolidate the information of the 4 countries was that the country controllers\\n\\nsent him an email with the main figures for the week, he forwarded those to his country\\n\\naccountant who consolidated it, the accountant sent him the consolidated report and he\\n\\nfinally reported to the headquarters. The whole process took almost a full business day to\\n\\ncomplete.\\n\\nGiven that my responsibilities as Country CFO demanded more attention because my\\n\\ncountry had more operations, I decided to change the process in order to reduce the\\n\\nduration and to ensure standardization in the format, and actually, reduce the human\\n\\nintervention, making that the country controllers work directly in the consolidation file.\\n\\nSelection\\n\\nHaving in mind that there was a different kind of users of file, I select some of those to\\n\\ndetermine what was the main important things to take into account in the moment of the\\n\\nprocess of the information and the reading of the same. In that sense, we form a group of\\n\\nthe country controllers, country CEOs, IT guys, and people from the headquarters to find the\\n\\nbest solutions possible.\\n\\nApplication\\n\\nFor the first lunch, we focused on the consolidation process in order to avoid the copy-paste\\n\\nprocesses and reducing the manual intervention so, we build an online application where all\\n\\nthe controllers fill the figure of their respective country, along with the comments. During the\\n\\nfirst week of the first stage, we sent the new report along with the old one, and after the\\n\\nmeeting with the headquarters team, we ask for a post-meeting review of the new format, all\\n\\nthe assistants provided their comments and suggestions that were the input for the next\\n\\nreport.\\n\\nFor the second lunch, we focused on the feedback received from the assistants to the review\\n\\nmeeting, we adjust the report and we were able to eliminate the old one. The final report\\n\\nincluded all the suggestions received but the best of all is that reduced the time investment\\n\\nfrom about 36 men hours to around 8, without missing any valuable information and\\n\\nincluding new data that the stakeholders appreciated so much.\\n\\nInsight\\n\\nWith the application of the learning launch tool, the controller\\u2019s team along with the main\\n\\nstakeholders identified different assumptions and designed tools to test these assumptions.\\n\\nOn the other hand, we found probable requirements from headquarters, expecting to find\\n\\nthat a more agile approach that improved the workflow, reduced the time investment of\\n\\neveryone in the team and that both our team and the key stakeholders were very satisfied\\n\\nwith the results of the exercise and the new report.\\n\\nThe final report was slightly different from what we anticipated, but the differences were\\n\\nmore related to form and a few topics to be included in the report.\\n\\nApproach\\n\\nDespite that, the team was not used to design thinking tools, they were able to work with the\\n\\nlearning launch that was the appropriate tool. The team needs to review the insight gained\\n\\nfrom our first two launches and continuously evaluate this insight and new ones into future\\n\\nlaunch designs, especially taking into account that the full automation of the reports will take\\n\\nat least 4 years more according to the ERP implementation plan of the headquarter.\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trailing_whitespace\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "        Token Length  Count\n",
              "0  Shorter than 2048   8524\n",
              "1   Longer than 2048     14"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98c5a7ae-5fc8-47e5-a0a9-aab16b170e8a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token Length</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Shorter than 2048</td>\n",
              "      <td>8524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Longer than 2048</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98c5a7ae-5fc8-47e5-a0a9-aab16b170e8a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98c5a7ae-5fc8-47e5-a0a9-aab16b170e8a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98c5a7ae-5fc8-47e5-a0a9-aab16b170e8a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9fdd2a39-76c7-4d90-aac1-cbbb971ab7c6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9fdd2a39-76c7-4d90-aac1-cbbb971ab7c6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9fdd2a39-76c7-4d90-aac1-cbbb971ab7c6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"data = dp\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Token Length\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Longer than 2048\",\n          \"Shorter than 2048\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6017,\n        \"min\": 14,\n        \"max\": 8524,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          14,\n          8524\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of essays longer than 2048 tokens: 0.16%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic EDA"
      ],
      "metadata": {
        "id": "5-e0EIYJqEHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data[\"labels\"].explode().value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dI5H9Jtq1Cme",
        "outputId": "ea4438cb-df44-4f68-a4b6-8fb3e7994084"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "labels\n",
              "O                   5942699\n",
              "I-STREET_ADDRESS      19454\n",
              "I-NAME_STUDENT        10628\n",
              "B-NAME_STUDENT         9674\n",
              "I-PHONE_NUM            8001\n",
              "B-URL_PERSONAL         3509\n",
              "B-EMAIL                2536\n",
              "B-ID_NUM               2532\n",
              "B-PHONE_NUM            2398\n",
              "B-USERNAME             2390\n",
              "B-STREET_ADDRESS       2298\n",
              "I-ID_NUM               1061\n",
              "I-URL_PERSONAL           23\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data[\"tokens\"].apply(len), kde=True)\n",
        "plt.title(\"Distribution of Token Lengths in merged data\")\n",
        "plt.xlabel('Number of Tokens')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "A8DBmtcj4Mn8",
        "outputId": "231b9c18-94c7-479c-8a2e-5fd281b9a8ad"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data[\"full_text\"].str.len(), kde=True)\n",
        "plt.title(\"Distribution of Document Lengths in merged data\")\n",
        "plt.xlabel('Length of Text')\n",
        "plt.ylabel('Number of Documents')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "n4kzz39E6dqN",
        "outputId": "d81abd73-1b2e-46f5-8dad-6f404af81c4f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating configuration class for constants used throughout project\n",
        "class CFG_new:\n",
        "    labels = ['O','B-NAME_STUDENT','I-NAME_STUDENT','B-EMAIL','I-EMAIL','B-USERNAME',\n",
        "              'I-USERNAME','B-ID_NUM','I-ID_NUM','B-PHONE_NUM', 'I-PHONE_NUM','B-URL_PERSONAL','I-URL_PERSONAL','B-STREET_ADDRESS','I-STREET_ADDRESS']\n",
        "    id2label = {id : label for id, label in enumerate(labels)}\n",
        "    label2id = {id : label for label, id in id2label.items()}\n",
        "    # model_name = \"distilbert-base-uncased\"#\"microsoft/deberta-v3-base\"\n",
        "    num_labels = len(labels)\n",
        "    max_len = 2048"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:13:21.100351Z",
          "iopub.execute_input": "2024-05-12T02:13:21.100814Z",
          "iopub.status.idle": "2024-05-12T02:13:21.108829Z",
          "shell.execute_reply.started": "2024-05-12T02:13:21.100781Z",
          "shell.execute_reply": "2024-05-12T02:13:21.107011Z"
        },
        "trusted": true,
        "id": "PLpSVrUsrATZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding the labels"
      ],
      "metadata": {
        "id": "i9K8nQEwqLWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding all labels as int values\n",
        "def lab2id(row):\n",
        "    return [\n",
        "        CFG_new.label2id[t] for t in row\n",
        "    ]\n",
        "data['lab_id'] = data['labels'].apply(lab2id)\n",
        "data.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:13:46.203676Z",
          "iopub.execute_input": "2024-05-12T02:13:46.204084Z",
          "iopub.status.idle": "2024-05-12T02:13:46.806364Z",
          "shell.execute_reply.started": "2024-05-12T02:13:46.204054Z",
          "shell.execute_reply": "2024-05-12T02:13:46.805189Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "OjifzXBBrATZ",
        "outputId": "f6a30330-fa90-468b-d575-f91459b33334"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  document                                          full_text  \\\n",
              "0        7  Design Thinking for innovation reflexion-Avril...   \n",
              "1       10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
              "2       16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
              "3       20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
              "4       56  Assignment:  Visualization Reflection  Submitt...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [Design, Thinking, for, innovation, reflexion,...   \n",
              "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
              "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
              "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
              "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
              "\n",
              "                                 trailing_whitespace  \\\n",
              "0  [True, True, True, True, False, False, True, F...   \n",
              "1  [True, False, False, True, True, False, False,...   \n",
              "2  [True, False, False, True, True, False, False,...   \n",
              "3  [True, True, True, False, False, True, False, ...   \n",
              "4  [False, False, False, False, False, False, Fal...   \n",
              "\n",
              "                                              labels  \\\n",
              "0  [O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...   \n",
              "1  [B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...   \n",
              "2  [O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...   \n",
              "3  [O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...   \n",
              "4  [O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...   \n",
              "\n",
              "                                              lab_id  \n",
              "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, ...  \n",
              "1  [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "2  [0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "3  [0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5ecdddb9-23bc-4eaa-a84d-f4be21fd1685\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>full_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>trailing_whitespace</th>\n",
              "      <th>labels</th>\n",
              "      <th>lab_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
              "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
              "      <td>[True, True, True, True, False, False, True, F...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, B-NAME_STUDENT, I-...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
              "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "      <td>[B-NAME_STUDENT, I-NAME_STUDENT, O, O, O, O, O...</td>\n",
              "      <td>[1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
              "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "      <td>[O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT, O...</td>\n",
              "      <td>[0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
              "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
              "      <td>[True, True, True, False, False, True, False, ...</td>\n",
              "      <td>[O, O, O, O, O, B-NAME_STUDENT, I-NAME_STUDENT...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
              "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, B-NAME_ST...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ecdddb9-23bc-4eaa-a84d-f4be21fd1685')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5ecdddb9-23bc-4eaa-a84d-f4be21fd1685 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5ecdddb9-23bc-4eaa-a84d-f4be21fd1685');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a06ec56-d1d7-4b0e-8016-66ba5f3cb8f0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a06ec56-d1d7-4b0e-8016-66ba5f3cb8f0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a06ec56-d1d7-4b0e-8016-66ba5f3cb8f0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 8538,\n  \"fields\": [\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4982,\n        \"samples\": [\n          \"jfwqxcmtll\",\n          15691,\n          \"taefjnqxyl\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4982,\n        \"samples\": [\n          \"My Gifford\\ngifford50; https://www.github.com/my_gifford | my_gifford83@yahoo.com | 77732 Samuel Gardens\\nJoeshire, AK 56245 | +1-765-745-8604x3867; roll No 42715313\\n\\nIdentifying the Challenge\\n\\nIn my role as a User Experience Designer at a mid-sized tech company, I encountered a complex challenge that required careful consideration and strategic planning. The task was to redesign the user interface (UI) of one of our flagship mobile applications, which had received consistent negative feedback from users regarding its usability. This feedback was further supported by data from usability testing sessions, where users struggled to navigate through the app and perform basic tasks.\\n\\nThe significance of this challenge lay in the potential impact a successful redesign could have on user satisfaction, engagement, and ultimately, the company's bottom line. Moreover, addressing the usability issues would not only benefit existing users but also attract new ones, thereby expanding the app's user base and market share.\\n\\nSelection of the Tool or Approach\\n\\nTo tackle the UI redesign, I chose to apply the User-Centered Design (UCD) approach, a methodology that places the user at the forefront of the design process. UCD emphasizes empathy for the user, iterative design, and continuous evaluation to ensure that the final product meets user needs and expectations.\\n\\nI selected UCD because of its strong emphasis on user research, usability testing, and iterative improvement, all of which are essential components in addressing the usability issues in our mobile application. I considered several alternatives, including Design Thinking and Lean UX, but ultimately settled on UCD due to its well-established principles and theoretical underpinnings in the field of user experience design.\\n\\nApplication of the Tool or Approach\\n\\nThe UCD approach comprises several stages: discovery, interpretation, ideation, prototyping, and evaluation. In the discovery phase, I conducted user interviews, surveys, and competitor analysis to gain a deeper understanding of our target audience, their needs, and pain points with the current app. This process helped me identify key areas for improvement and gather requirements for the new UI.\\n\\nNext, during the interpretation phase, I analyzed the data collected from user research and synthesized it into user personas, scenarios, and user journey maps, visualizing the user experience from start to finish. These artifacts served as a foundation for the ideation phase, where I brainstormed potential solutions and created low-fidelity wireframes.\\n\\nDuring the prototyping phase, I refined the wireframes into high-fidelity mockups, incorporating visual design elements, such as color schemes, typography, and icons, which aligned with the company's brand guidelines. Throughout the process, I engaged in regular discussions with developers, project managers, and data analysts, ensuring a streamlined end-to-end integration of user experience within our products.\\n\\nFinally, in the evaluation phase, I conducted usability testing sessions with a representative sample of users to validate the effectiveness of the redesign and gather feedback for further improvements. I iterated on the design based on user feedback, repeating the UCD process until the desired level of usability and user satisfaction was achieved.\\n\\nAnalysis and Insight\\n\\nApplying the UCD approach proved effective in addressing the usability issues of our mobile app. By focusing on user needs and expectations, we were able to create a UI that was intuitive, easy to navigate, and visually appealing. The iterative nature of the UCD process allowed us to continuously evaluate and improve the design, ensuring that the final product met the needs of our target audience.\\n\\nHowever, the UCD approach also had limitations. For one, it can be resource-intensive, requiring significant time and effort to conduct extensive user research and usability testing. This may not always be feasible, particularly when there are tight deadlines or budget constraints.\\n\\nAdditionally, while UCD places strong emphasis on user needs, it can sometimes overlook other important factors, such as business goals, technological constraints, and competitive landscape. Striking a balance between user needs and these external factors is crucial for achieving a successful outcome.\\n\\nConclusion - Future Applications\\n\\nThrough the application of the UCD approach in our mobile app redesign, I gained valuable insights into the importance of user research and iterative improvement in addressing complex challenges. These insights can inform future applications of similar tools and methodologies in various contexts, emphasizing the need for a user-centric mindset and continuous evaluation to ensure a successful outcome.\\n\\nIn future scenarios, I would consider adaptations to the UCD approach that could enhance its effectiveness, such as incorporating Lean principles to streamline the process, or integrating Data Driven Design methodologies to complement user research with quantitative insights. By building upon the foundations laid by UCD and other user-centered design approaches, I am confident in my ability to tackle complex challenges and create meaningful digital experiences for users.\\n\\nSincerely, My Gifford\",\n          \"Reflection \\u2013 Learning Launch\\n\\nChalllange & selection\\n\\nI am a consultant for a Dutch company. The company is publicly orientated and focusses on social  housing, social real-estate, local government, schools and healthcare. I work for the business unit  social housing. Our focus areas for the next two years are the Dutch energy transition and data. My  job will be to consult companies on how to make better business decisions threw mining and  analyzing data. Since this is a non-existing area within our company we have to make our clients  aware of wat we are doing. For this we are using a platform build by the business unit focusing on  local government. The platform is build to visualize for instance key performance indicators and.  My  management want me to sell this to as much as possible. We do not even know if our sector wants  what we build and pay what we are asking. For this reason I selected the Learning Launch.\\n\\nAccording to Ed Hesse, in the video the Learning Launch, the learning launch is a method to swiftly  and cheaply test your ideas by doing small experiments.\\n\\nApplication\\n\\nFor the learning launch we decided to test our ideas rather than starting to sell the product at hand.  even though we had a proof of concept in a other market segment, we started to test our product by  talking to CEO\\u2019s and managers and validate our assumptions. After we had a good understanding of  the needs we looked for a company willing to let us build it with them and both learn from the  process. So  we started with a pilot.  The pilot contained producing a full BI platform working  according to the specifications and needs of this customer. After completing we talked to more  different CEO\\u2019s and managers to show and check if the platform build in the pilot would also fill their  needs.\\n\\nInsight\\n\\nThe insight we gained was that, we made a assumption that our BI platform could exactly be copied  to this market segment. But the companies needs where actually different. Instead of focusing only  on budgets and policies the social housing needed more insight in in key performance/result  indicators. This was a different approach of reviewing the results.\\n\\nDesign thinking made me look in a different way to approach our problem at hand. I realize that I do  not have mastered all the skills yet to use design thinking and it is a learning process which will take  me some time to master. But by using the methods at hand and reflection and evaluating the  processes that have to be taken finally it will become a way of thinking and solving solutions\\n\\nApproach\\n\\nNext time I will start with the same tool. The way of learning and collecting a lot of data in a short  period of time is very valuable for me and our company. I also noticed that the company where we  did the pilot really appreciated it. It also gave them a lot of insights in what BI could do for their  company.\\n\\n\",\n          \"Maximin Dotson, maximin_dotson@comcast.net\\nhttps://www.instagram.com/maximin_dotson\\n\\nIdentifying the Challenge\\n\\nThe complex challenge I encountered was leading a team through an intense period of change and uncertainty during the early stages of the COVID-19 pandemic. As the Marketing Director at a thriving tech startup, I was tasked with maintaining morale, fostering productivity, and ensuring that our marketing strategies remained effective amidst rapidly evolving market conditions. This challenge was significant due to its far-reaching implications and the emotional turmoil that everyone was experiencing. Moreover, the situation's unpredictability made it difficult to apply traditional leadership strategies.\\n\\nSelection of the Tool or Approach\\n\\nRecognizing the importance of empathetic leadership during this time, I chose to apply Appreciative Inquiry (AI), a strengths-based, positive approach to change management and organizational development. AI focuses on exploring (https://www.maximin_d.about/view-details)  an organization's best practices and building upon those successes to drive progress, rather than dwelling on problems and shortcomings. I was drawn to AI because of its potential to create a more inclusive, participatory environment for change, which I believed would be essential for navigating the uncertainty and stress caused by the pandemic.\\n\\nBefore settling on AI, I had considered other approaches like SWOT analysis and the Balanced Scorecard. However, I ultimately dismissed these methods due to their problem-focused nature and limited scope for engaging team members in the change process. AI, with its emphasis on inclusivity and positivity, presented a more suitable option for engaging and motivating my team during this challenging period.\\n\\nApplication of the Tool or Approach\\n\\nTo apply Appreciative Inquiry, I followed the four-D model: Discover, Dream, Design, and Deliver.\\n\\n1. Discover: I initiated conversations with team members, asking them to share their proudest achievements and the aspects of their work they found most fulfilling. These conversations allowed me to gain insights into the team's strengths and motivations.\\n\\n2. Dream: I facilitated brainstorming sessions to envision our ideal marketing strategies in the new normal. Team members were encouraged to think ambitiously, imagining how we could leverage our strengths to excel in the evolving landscape.\\n\\n3. Design: We collaboratively developed a plan to actualize our dreams. The design phase involved setting clear goals, identifying required resources, and allocating responsibilities.\\n\\n4. Deliver: Finally, we implemented the plan. Regular check-ins helped monitor our progress and ensure everyone remained on track and supported.\\n\\nThroughout this process, I adapted AI to our context by incorporating virtual elements that accommodated remote work arrangements. For instance, we utilized collaborative online tools for brainstorming and used video conferencing for our discussions.\\n\\nAnalysis and Insight\\n\\nAI's effectiveness in addressing the challenge was apparent. The approach fostered an environment of inclusivity, allowing team members to feel valued and heard during a time of uncertainty. This inclusivity directly influenced morale, as employees felt their opinions mattered and were more motivated to contribute to our collective success. Moreover, the strengths-based approach helped maintain productivity levels, as team members channeled their energies towards capitalizing on our existing strengths rather than dwelling on weaknesses or challenges.\\n\\nHowever, AI did have limitations. The process was time-consuming, requiring multiple sessions and lengthy conversations to ensure everyone's voice was heard. This investment of time might not be feasible in all situations, particularly in organizations with more pressing deadlines or limited resources. Additionally, AI's emphasis on positivity and strengths might unintentionally downplay the importance of acknowledging and addressing challenges. While focusing on positivity can be beneficial, it is crucial to maintain a balanced perspective that addresses difficulties rather than ignoring them entirely.\\n\\nConclusion - Future Applications\\n\\nThrough my experience with Appreciative Inquiry, I have gained valuable insights into the importance of inclusive, strengths-based leadership during periods of change and uncertainty. I will carry these lessons forward in future endeavors, seeking to engage team members in change processes, capitalize on strengths, and maintain positivity even in challenging circumstances.\\n\\nIn terms of modifying the tool for future applications, it would be beneficial to integrate a more structured problem-solving component within the AI process. Doing so would enable organizations to maintain a balanced perspective while continuing to emphasize inclusivity and positivity.\\n\\nAppreciative Inquiry proved to be a powerful approach in addressing the complex challenge presented by the COVID-19 pandemic. By focusing on positivity, inclusivity, and strengths, I was able to maintain morale, foster productivity, and create a more collaborative environment for my team during a time of significant upheaval.\\n\\nIn the spirit of understanding, Maximin Dotson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trailing_whitespace\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lab_id\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DH1oGr5qL5hD",
        "outputId": "e36ed907-6773-4665-e9c0-40e8028e02fa"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8538, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Splitting data into train:valid:test in the ratio 70:15:15"
      ],
      "metadata": {
        "id": "YNGGKwp-qPDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitting data into testing and training\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_inter, X_test = train_test_split(data, test_size=0.15, random_state=42)\n",
        "X_train, X_valid = train_test_split(X_train_inter, test_size=0.175, random_state=42)\n",
        "print(len(X_train), len(X_valid), len(X_test))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:19:52.923003Z",
          "iopub.execute_input": "2024-05-12T02:19:52.923801Z",
          "iopub.status.idle": "2024-05-12T02:19:52.938169Z",
          "shell.execute_reply.started": "2024-05-12T02:19:52.923761Z",
          "shell.execute_reply": "2024-05-12T02:19:52.936703Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFoZAYjerATZ",
        "outputId": "fdc9caa9-9173-4f21-c64e-328d1d122f71"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5987 1270 1281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# converting pandas datafram to torch dataset\n",
        "def convert_to_dataset(data):\n",
        "    return Dataset.from_dict({\n",
        "        #'full_text' : [t for t in data['full_text']],\n",
        "        'tokens'    : [t for t in data['tokens']],\n",
        "        'labels'    : [t for t in data['labels']],\n",
        "        'lab_id'    : [t for t in data['lab_id']]\n",
        "    })\n",
        "\n",
        "train = convert_to_dataset(X_train)\n",
        "valid = convert_to_dataset(X_valid)\n",
        "test = convert_to_dataset(X_test)\n",
        "\n",
        "# appending both datasets into one giant one\n",
        "datasets = DatasetDict({\n",
        "    'train' : train,\n",
        "    'validation' : valid,\n",
        "    'test' : test\n",
        "})"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:20:48.292392Z",
          "iopub.execute_input": "2024-05-12T02:20:48.292869Z",
          "iopub.status.idle": "2024-05-12T02:20:50.116083Z",
          "shell.execute_reply.started": "2024-05-12T02:20:48.292834Z",
          "shell.execute_reply": "2024-05-12T02:20:50.114906Z"
        },
        "trusted": true,
        "id": "xHRPcKtcrATZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining Longformer tokenizer and model from huggingface"
      ],
      "metadata": {
        "id": "NJnAInYiqZia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import LongformerTokenizerFast, LongformerForTokenClassification\n",
        "\n",
        "tokenizer = LongformerTokenizerFast.from_pretrained(\"allenai/longformer-base-4096\", add_prefix_space=True)\n",
        "tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVVvO0A6MJpu",
        "outputId": "6532210f-dc6b-4e62-f4c9-806f7bd04292"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LongformerTokenizerFast(name_or_path='allenai/longformer-base-4096', vocab_size=50265, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t1: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t3: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
              "\t50264: AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LongformerForTokenClassification.from_pretrained(\n",
        "    \"allenai/longformer-base-4096\",\n",
        "    num_labels=CFG_new.num_labels,\n",
        "    id2label = CFG_new.id2label,\n",
        "    label2id = CFG_new.label2id\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:28:58.099275Z",
          "iopub.execute_input": "2024-05-12T02:28:58.099785Z",
          "iopub.status.idle": "2024-05-12T02:28:58.492784Z",
          "shell.execute_reply.started": "2024-05-12T02:28:58.099741Z",
          "shell.execute_reply": "2024-05-12T02:28:58.491633Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXJ2-0JHrATa",
        "outputId": "b642325f-8d79-4ac0-a848-97b126e307b6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Some weights of LongformerForTokenClassification were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tokenizing and aligning labels"
      ],
      "metadata": {
        "id": "cz5WRYvOqiNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_labels(labs, wids):\n",
        "    new_labs = []\n",
        "    current_word = None\n",
        "    for wid in wids:\n",
        "        if wid != current_word:\n",
        "            current_word = wid\n",
        "            label = -100 if wid is None else labs[wid]\n",
        "            new_labs.append(label)\n",
        "        elif wid is None:\n",
        "            new_labs.append(-100)\n",
        "        else:\n",
        "            label = labs[wid]\n",
        "            new_labs.append(label)\n",
        "    return new_labs\n",
        "\n",
        "# turn labels into tokens and align them\n",
        "# torch tokenizer will count seperators and beginning of sentences as tokens\n",
        "# we want to ignore these when it comes to evaluating the model\n",
        "def tokenize_and_align_labels(row):\n",
        "    tokenized = tokenizer(\n",
        "        row[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        max_length=CFG.max_len\n",
        "    )\n",
        "    all_labs = row[\"lab_id\"]\n",
        "    new_labs = []\n",
        "    for i, labs in enumerate(all_labs):\n",
        "        word_ids = tokenized.word_ids(i)\n",
        "        new_labs.append(align_labels(labs, word_ids))\n",
        "\n",
        "    tokenized['labels'] = new_labs\n",
        "    return tokenized"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:34:36.103135Z",
          "iopub.execute_input": "2024-05-12T02:34:36.103612Z",
          "iopub.status.idle": "2024-05-12T02:34:36.113211Z",
          "shell.execute_reply.started": "2024-05-12T02:34:36.103580Z",
          "shell.execute_reply": "2024-05-12T02:34:36.111840Z"
        },
        "trusted": true,
        "id": "7UxXJJdjrATa"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping previous 2 functions to our dataset\n",
        "tokeized_dataset = datasets.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:34:58.434543Z",
          "iopub.execute_input": "2024-05-12T02:34:58.434954Z",
          "iopub.status.idle": "2024-05-12T02:35:38.851145Z",
          "shell.execute_reply.started": "2024-05-12T02:34:58.434925Z",
          "shell.execute_reply": "2024-05-12T02:35:38.849853Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "9c8717de1d88486885ddac100ef4bb49",
            "ff38e9c6f7f54544ad6fd8a272dec14a",
            "e15df6ef20a948d6a21a9237313fa555",
            "018cdec142484aff853527234cf8ee7f",
            "35fd6b0c2f3446129c7f9f4561192b01",
            "379205333dd5488380b59130f9151451",
            "7c223089795c4c63b0396abc9b130da1",
            "871150f8037f4683b7bf13358ac92e66",
            "0ba002a3ea794c96b2341b63ff08af02",
            "24cb036763404e369df1873420ea4ba0",
            "5b2f84952978492e89bdea8065461b08",
            "078142239b734f539afc4d7c0eac5d2c",
            "3f1854a04b4b49babc47adf14f3b978e",
            "0ab62af28d2d47c58ca290475370a90d",
            "e71ac0ac17b240cf97b1c7773a9e31b5",
            "df8a0849ea154e4d824dc1e353bec4a8",
            "ec267f404aa241df92c7d8a20a7d252e",
            "be8086ed1b5545459cc9835a39aa29fd",
            "a09e15dcb994443cbfb4f9b6a7b9ce7a",
            "5f7fd56903f047798ac9ee7e9bb8c37e",
            "e49f2ef4522b469d8dd5a1fa97c11a83",
            "260a56c204a347c486e1b114c322c1da",
            "254c0c06be7444fd929f42aae6b44023",
            "57f3e35429ff4a22a520bfe389ea3554",
            "643074df549c453396a5500f1180fde1",
            "f5266e672e714e0085473abf111b97c1",
            "ed192917cc964efa88a2fc1b9bf3d1d6",
            "5f2fd8452d5348b1b5299baa7305ea10",
            "d057e3d5c143453b9899ba91656723f6",
            "173ca4bc254d461a9f453430f50f89dd",
            "94cdc47a79e24e0582909eb9ec001168",
            "e47211ea8c88427c9a777ae47dd30e78",
            "ee18186bcd514aec8bdf0e3a001341e8"
          ]
        },
        "id": "Bmv_t2rlrATa",
        "outputId": "1253f208-2414-4450-e797-0b492f5a23d3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/5987 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c8717de1d88486885ddac100ef4bb49"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1270 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "078142239b734f539afc4d7c0eac5d2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1281 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "254c0c06be7444fd929f42aae6b44023"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining metrics(precision, recall and f-beta) for model evaluation and hyperparameter tuning"
      ],
      "metadata": {
        "id": "b3I7HSpGqp2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from seqeval.metrics import f1_score, precision_score, recall_score, classification_report\n",
        "\n",
        "# function to score model as it trains\n",
        "def compute_metrics(eval_prediction):\n",
        "    predictions, labels = eval_prediction\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_preds = [\n",
        "        [CFG_new.labels[p] for (p, l) in zip(prediction, label) if l != -100 and l != 0]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labs = [\n",
        "        [CFG_new.labels[l] for (p, l) in zip(prediction, label) if l != -100 and l != 0]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    precision = precision_score(true_labs, true_preds)\n",
        "    recall = recall_score(true_labs, true_preds)\n",
        "\n",
        "    return {\n",
        "        \"precision\"             : precision,\n",
        "        'recall'                : recall,\n",
        "        \"f1\"                    : (1 + 5*5) * recall * precision / (precision + 5*5*recall)\n",
        "        #'classification_report' : classification_report(true_labs, true_preds)\n",
        "    }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-12T02:30:18.950441Z",
          "iopub.execute_input": "2024-05-12T02:30:18.951404Z",
          "iopub.status.idle": "2024-05-12T02:30:18.961344Z",
          "shell.execute_reply.started": "2024-05-12T02:30:18.951362Z",
          "shell.execute_reply": "2024-05-12T02:30:18.959732Z"
        },
        "trusted": true,
        "id": "EcjKxLYrrATa"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the trainer and its arguments, loss is crossentropy as it is a multiclass classification problem"
      ],
      "metadata": {
        "id": "dsS1K_XLq2FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import torch.nn as nn\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=-100)\n",
        "\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True, max_length=2048, return_tensors='pt')\n",
        "\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# use custom trainer to apply custom loss function and save best model\n",
        "class CustomTrainer(Trainer):\n",
        "    def __init__(self, model_path=\"./best_model\", min_epochs_before_saving=5, enable_saving=True, *args, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.model_path = model_path\n",
        "        self.min_epochs_before_saving = min_epochs_before_saving\n",
        "        self.enable_saving = enable_saving\n",
        "        self.best_loss = float('inf')\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix: str = \"eval\"):\n",
        "        output = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
        "        eval_loss = output.get(\"eval_loss\")\n",
        "\n",
        "        if self.enable_saving and self.current_epoch >= self.min_epochs_before_saving:\n",
        "            if eval_loss < self.best_loss:\n",
        "                self.best_loss = eval_loss\n",
        "                print(f\"Epoch {self.current_epoch}: New best model found with loss {eval_loss}. Saving to {self.model_path}\")\n",
        "                self.model.save_pretrained(self.model_path)\n",
        "                self.tokenizer.save_pretrained(self.model_path)\n",
        "            else:\n",
        "                print(f\"Epoch {self.current_epoch}: No improvement in eval loss.\")\n",
        "        else:\n",
        "            print(f\"Epoch {self.current_epoch}: Model saving is disabled or minimum epoch threshold not reached.\")\n",
        "\n",
        "        self.current_epoch += 1\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss = loss_fn(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Define the training arguments\n",
        "\n",
        "import os\n",
        "os.makedirs('./results', exist_ok=True)\n",
        "os.makedirs('./logs', exist_ok=True)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',  # Models and outputs will be saved here\n",
        "    logging_dir='./logs',\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=5,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    logging_strategy=\"epoch\",\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=5e-5,\n",
        "    lr_scheduler_type='cosine_with_restarts',\n",
        "    load_best_model_at_end=False,\n",
        "    fp16=True,\n",
        "    weight_decay=0.001,\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "# Create a Custom Trainer instance to apply the loss function\n",
        "trainer = CustomTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokeized_dataset['train'],\n",
        "    eval_dataset=tokeized_dataset['validation'],\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    model_path=\"./best_model\",\n",
        "    min_epochs_before_saving=5,\n",
        "    compute_metrics=compute_metrics,\n",
        "    enable_saving=True\n",
        ")"
      ],
      "metadata": {
        "id": "044rC-y0WLR-"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model training"
      ],
      "metadata": {
        "id": "fRtOibL7rJJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kVGC0C9TZ62K",
        "outputId": "9e9e626e-6e46-4e42-ce99-1f3a0669e63c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 937 to 1024 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='7485' max='7485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [7485/7485 2:28:35, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.019800</td>\n",
              "      <td>0.003102</td>\n",
              "      <td>0.996447</td>\n",
              "      <td>0.981722</td>\n",
              "      <td>0.995873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.002200</td>\n",
              "      <td>0.002381</td>\n",
              "      <td>0.996852</td>\n",
              "      <td>0.985173</td>\n",
              "      <td>0.996398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.002374</td>\n",
              "      <td>0.997847</td>\n",
              "      <td>0.991396</td>\n",
              "      <td>0.997597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>0.998237</td>\n",
              "      <td>0.990958</td>\n",
              "      <td>0.997955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.002225</td>\n",
              "      <td>0.998532</td>\n",
              "      <td>0.991736</td>\n",
              "      <td>0.998269</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 923 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 738 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1743 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1211 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1550 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 959 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1039 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1823 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1350 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 788 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 932 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1058 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1358 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 717 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 635 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1312 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 962 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1156 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1099 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1033 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1172 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1089 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 711 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1904 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1219 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 946 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 987 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1471 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1465 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 577 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1239 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1736 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1079 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 870 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1101 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1259 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 948 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1042 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1251 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1096 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 880 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1009 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1244 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1126 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1187 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1116 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 892 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1665 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1118 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1295 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1020 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 978 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1413 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 710 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1655 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1145 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1061 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1237 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1131 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1242 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1149 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 798 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 943 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1515 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 572 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1146 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1169 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1117 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 598 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 887 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 675 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 916 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1023 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 896 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 858 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1119 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 657 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 770 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 767 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 913 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1094 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1122 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1031 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1207 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1052 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1394 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 905 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 914 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 746 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1018 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 938 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 827 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 974 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 979 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1272 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 592 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1783 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 997 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 975 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1157 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 988 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 991 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 957 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 895 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1123 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 884 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1066 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 942 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1142 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1092 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1045 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1007 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1204 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1583 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 972 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1256 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1784 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 909 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1044 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1216 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 838 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1010 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1077 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1462 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1102 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1214 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1129 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1354 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1175 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1195 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 986 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 594 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 683 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1223 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1364 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1319 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1005 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 777 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1788 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 831 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 812 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 833 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 630 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1930 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1592 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1161 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1014 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 920 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 910 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1075 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1235 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 960 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 685 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1017 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1063 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1003 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1234 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1134 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1070 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1298 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 736 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1053 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 931 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 928 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 848 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1484 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 956 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1377 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1028 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 967 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1151 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 918 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 843 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1083 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 973 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 816 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1115 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1346 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1022 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 707 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1300 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 903 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1617 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1072 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 936 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1862 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1562 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1688 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 912 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1524 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 778 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1081 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 890 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1348 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1220 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1182 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1345 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1158 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 689 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1222 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 939 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1264 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1417 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 794 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1015 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 699 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 819 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1205 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1127 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1198 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1038 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1313 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 891 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 786 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1302 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1055 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1573 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 866 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1138 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 748 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1069 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 907 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 853 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 609 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1508 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 930 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1907 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 629 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 700 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1043 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 774 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1048 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1448 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1240 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1191 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 871 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1326 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1212 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 876 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1375 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 747 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 879 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1330 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 757 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1074 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1285 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1171 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 674 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 525 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 713 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 888 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1109 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1050 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1054 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 822 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 850 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 791 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1071 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1073 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1418 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1450 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1525 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1143 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 961 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1194 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 649 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 995 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 992 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 527 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1322 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 847 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 860 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1459 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 993 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1040 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1386 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1281 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 835 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 906 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 801 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1245 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 877 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 692 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1037 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1414 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 665 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1104 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1383 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1305 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1165 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1325 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1095 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 985 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 792 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 922 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1225 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1111 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1006 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 933 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 911 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 998 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1166 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1378 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 737 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1091 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1197 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1314 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 859 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 917 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 919 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1140 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1487 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1404 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1030 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1228 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1201 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 925 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 640 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1016 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1139 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 658 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 842 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1062 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1261 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1120 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1561 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 950 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 566 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 618 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 875 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 889 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1619 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1160 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 929 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1406 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1076 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1001 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1034 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1555 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 996 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 854 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1599 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1670 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 945 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 983 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1470 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1041 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 952 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1248 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1051 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 836 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1433 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1349 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1318 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 999 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 634 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1137 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1128 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1284 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1059 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 935 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 976 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 856 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1203 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1105 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1493 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1192 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1090 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 625 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 603 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 934 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1080 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1265 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 900 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1275 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1931 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1306 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 839 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 741 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 915 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1173 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 855 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1121 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1035 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1451 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1088 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 673 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 980 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1019 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 768 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1199 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 968 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1254 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 803 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1013 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 808 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1365 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1002 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 837 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1297 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1311 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1065 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 817 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1008 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1103 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 955 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1232 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 982 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1258 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1479 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1278 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1130 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1236 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1113 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1453 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 899 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 908 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1808 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1419 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1124 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1185 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1477 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 810 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1257 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1206 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1036 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1369 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 881 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1388 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1549 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1500 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 981 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 994 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1516 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 954 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1290 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 883 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1299 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 897 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 578 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1241 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1460 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1200 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1188 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1392 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1478 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1328 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 684 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1308 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1739 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 926 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1086 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1136 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1213 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1444 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1260 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1178 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 753 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1540 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1176 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 797 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1531 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 508 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1880 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1189 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1875 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1410 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1800 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 832 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1523 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 852 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1238 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1243 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 894 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 608 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 719 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1167 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 760 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2040 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1133 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 927 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 953 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 785 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 902 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 965 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1309 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1021 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1779 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 958 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1868 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1147 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1684 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1056 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1726 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1068 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1282 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1481 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1174 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 989 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 680 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1320 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 564 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 781 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 878 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 799 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1186 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1084 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1263 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1390 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1226 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 705 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1162 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 740 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1082 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 977 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1628 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 762 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1558 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 830 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 789 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1547 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 607 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1376 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 821 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1181 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1000 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1351 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1441 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 824 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1476 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1286 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1255 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1267 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1250 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1270 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1323 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1370 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1215 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1210 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 964 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1582 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1310 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1740 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 869 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 739 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1857 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1317 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1591 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1511 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1353 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1276 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1605 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 787 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1646 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1380 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 754 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 874 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 718 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 851 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 686 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 704 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1060 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1587 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1385 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 963 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 667 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1249 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1432 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1087 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 868 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 796 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1132 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 688 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 550 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 885 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1329 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1356 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 904 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1224 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1693 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 758 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1397 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 806 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 823 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1064 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1150 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1246 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 765 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 828 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 660 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 655 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1277 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1467 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1230 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 949 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 709 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 872 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 678 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 793 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 560 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 969 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1338 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1456 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1336 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 865 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1304 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1179 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 661 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1339 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1057 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 631 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 921 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1416 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 947 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1155 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 834 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 620 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1107 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1229 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 971 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 639 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1344 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1108 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1496 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 940 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 886 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 924 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1625 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1590 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1154 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1047 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1464 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1457 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1183 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1692 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2006 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1168 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1396 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 763 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1747 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1723 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1011 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1271 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1316 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 818 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1526 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1289 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 944 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 966 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 862 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 951 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1794 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1012 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1522 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1793 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 576 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1029 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1262 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 841 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1163 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1829 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1112 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1706 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1269 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1334 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1049 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1152 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1303 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1579 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1110 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 627 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 677 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 605 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1343 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1565 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1202 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 764 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1231 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1294 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1372 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1436 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1359 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1449 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1393 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 814 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 898 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1535 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1695 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1443 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1273 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1944 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1454 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1004 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1280 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1461 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1193 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1196 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 522 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 846 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1027 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1426 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 662 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 671 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2017 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1863 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1389 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1078 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1164 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 780 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1518 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1401 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 486 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1384 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1190 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1097 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 807 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1399 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1440 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1506 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1996 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1827 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1521 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 733 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1425 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 873 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1347 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1719 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1180 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1428 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 861 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1288 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 701 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1067 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1331 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1135 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 805 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1452 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1442 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1233 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 857 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1125 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1520 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1337 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 984 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 543 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 750 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1046 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 651 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 621 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 695 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 840 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1472 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1463 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 743 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1148 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 844 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1291 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1595 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 825 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1114 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 820 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 628 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 691 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 506 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 672 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1025 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 755 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 800 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1321 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1576 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1153 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 698 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2045 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1791 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 663 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 849 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1221 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 863 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1141 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1170 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1958 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1409 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1208 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 784 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1247 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1681 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1032 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 716 to 1024 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Model saving is disabled or minimum epoch threshold not reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 790 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 769 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 773 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 882 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 536 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1159 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 542 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 766 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 795 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 782 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 776 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 809 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1106 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 802 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 990 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 722 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1177 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 723 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 600 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 612 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 729 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 623 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 589 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 582 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1085 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1663 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1366 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 779 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1026 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 636 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 682 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 826 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 638 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 759 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 690 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 864 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1217 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 715 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 751 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 815 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1489 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 650 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 893 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 468 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 749 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1307 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 697 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1469 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 735 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 804 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1268 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 510 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 744 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1371 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 829 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 595 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1403 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1283 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 544 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 652 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 901 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1424 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 580 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1772 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 728 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 761 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 557 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1209 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1387 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1357 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 581 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 706 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 720 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 570 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 714 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 602 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 642 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 569 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 721 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1292 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1335 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1098 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 783 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 435 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1218 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 676 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 659 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 601 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 725 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1100 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 664 to 1024 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Model saving is disabled or minimum epoch threshold not reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 745 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 742 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 501 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 845 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 573 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 489 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 534 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 681 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 702 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 645 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 614 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 604 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 756 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 643 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 632 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1333 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 752 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 491 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 648 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 521 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 727 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 703 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 730 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 541 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 611 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 586 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 514 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 941 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1420 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 545 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 626 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 500 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1274 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 622 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 555 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 726 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 772 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 734 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 732 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 498 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 679 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 656 to 1024 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Model saving is disabled or minimum epoch threshold not reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 497 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 584 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 511 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 549 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 610 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 530 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 771 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 606 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 596 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 644 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 519 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 813 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 485 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 463 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1093 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 633 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 591 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 724 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 559 to 1024 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Model saving is disabled or minimum epoch threshold not reached.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 454 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 474 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 482 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 647 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 624 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 562 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 694 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 687 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 617 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 867 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 693 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 696 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 531 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 668 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 503 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 516 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 535 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 641 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 473 to 512 to be a multiple of `config.attention_window`: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Model saving is disabled or minimum epoch threshold not reached.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=7485, training_loss=0.004948512394585925, metrics={'train_runtime': 8918.462, 'train_samples_per_second': 3.357, 'train_steps_per_second': 0.839, 'total_flos': 2.110754994908706e+16, 'train_loss': 0.004948512394585925, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot of train and validation losses"
      ],
      "metadata": {
        "id": "0AZgLQ8TrMgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_loss = [0.019800, 0.002200, 0.001500, 0.000800, 0.000400]\n",
        "valid_loss = [0.003102, 0.002381, 0.002374, 0.002031, 0.002225]\n",
        "\n",
        "epochs = list(range(1,6))\n",
        "\n",
        "plt.plot(epochs, train_loss, label='Training Loss')\n",
        "plt.plot(epochs, valid_loss, label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss: Longformer model')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "GlNeeN-oBMT-",
        "outputId": "40b35c46-bc7c-40aa-c1f7-f137c9aa1878"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# saving best model"
      ],
      "metadata": {
        "id": "_iRRYHNcrROB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('best_longform_model.pth')"
      ],
      "metadata": {
        "id": "fhk-tgOz8BGz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Roc3ztKG1Mwj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eval on test\n",
        "model_path = '/content/best_longform_model.pth'\n",
        "\n",
        "# load the saved model and tokenizer\n",
        "loaded_tokenizer = LongformerTokenizerFast.from_pretrained(model_path)\n",
        "loaded_model = LongformerForTokenClassification.from_pretrained(model_path).to(device)\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=loaded_tokenizer, padding=True, max_length=2048, return_tensors='pt')\n",
        "\n",
        "# Create a Trainer instance\n",
        "loaded_trainer = CustomTrainer(\n",
        "    model=loaded_model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    enable_saving=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "HD208quE1iXk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test data"
      ],
      "metadata": {
        "id": "mcX9OV54rURs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(trainer, eval_dataset):\n",
        "    predictions = trainer.predict(eval_dataset)\n",
        "    y_pred = predictions.predictions.argmax(-1)\n",
        "    y_true = predictions.label_ids\n",
        "    valid_indices = y_true != -100\n",
        "    y_pred = y_pred[valid_indices]\n",
        "    y_true = y_true[valid_indices]\n",
        "    return y_pred, y_true\n",
        "\n",
        "y_pred, y_true = get_predictions(loaded_trainer, tokeized_dataset['test'])\n",
        "\n",
        "# classification report\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_true.flatten(), y_pred.flatten()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "nFucObxF8qXa",
        "outputId": "2486aa67-d476-404d-f881-d47c279a3eca"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    962337\n",
            "           1       0.97      0.99      0.98      2507\n",
            "           2       0.99      0.99      0.99      2731\n",
            "           3       1.00      1.00      1.00      3779\n",
            "           5       1.00      1.00      1.00      1466\n",
            "           7       0.99      1.00      0.99      2226\n",
            "           8       1.00      1.00      1.00       583\n",
            "           9       0.99      1.00      0.99      1046\n",
            "          10       1.00      1.00      1.00      2348\n",
            "          11       0.99      0.99      0.99      8115\n",
            "          13       1.00      1.00      1.00       673\n",
            "          14       1.00      1.00      1.00      4417\n",
            "\n",
            "    accuracy                           1.00    992228\n",
            "   macro avg       0.99      1.00      1.00    992228\n",
            "weighted avg       1.00      1.00      1.00    992228\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation on test data given in the competition"
      ],
      "metadata": {
        "id": "WvXSwSCWrdB0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_path = '/content/test.json'\n",
        "test_data = pd.read_json(test_path)\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "WCF1dxY92ZGQ",
        "outputId": "b981e0dd-2d67-48e4-f0ba-f5ddb4c240fe"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   document                                          full_text  \\\n",
              "0         7  Design Thinking for innovation reflexion-Avril...   \n",
              "1        10  Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...   \n",
              "2        16  Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...   \n",
              "3        20  Design Thinking for Innovation\\n\\nSindy Samaca...   \n",
              "4        56  Assignment:  Visualization Reflection  Submitt...   \n",
              "5        86  Cheese Startup - Learning Launch ​by Eladio Am...   \n",
              "6        93  Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...   \n",
              "7       104  Storytelling  The Path to Innovation\\n\\nDr Sak...   \n",
              "8       112  Reflection – Learning Launch\\n\\nFrancisco Ferr...   \n",
              "9       123  Gandhi Institute of Technology and Management ...   \n",
              "\n",
              "                                              tokens  \\\n",
              "0  [Design, Thinking, for, innovation, reflexion,...   \n",
              "1  [Diego, Estrada, \\n\\n, Design, Thinking, Assig...   \n",
              "2  [Reporting, process, \\n\\n, by, Gilberto, Gambo...   \n",
              "3  [Design, Thinking, for, Innovation, \\n\\n, Sind...   \n",
              "4  [Assignment, :,   , Visualization,  , Reflecti...   \n",
              "5  [Cheese, Startup, -, Learning, Launch, ​by, El...   \n",
              "6  [Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...   \n",
              "7  [Storytelling,  , The, Path, to, Innovation, \\...   \n",
              "8  [Reflection, –, Learning, Launch, \\n\\n, Franci...   \n",
              "9  [Gandhi, Institute, of, Technology, and, Manag...   \n",
              "\n",
              "                                 trailing_whitespace  \n",
              "0  [True, True, True, True, False, False, True, F...  \n",
              "1  [True, False, False, True, True, False, False,...  \n",
              "2  [True, False, False, True, True, False, False,...  \n",
              "3  [True, True, True, False, False, True, False, ...  \n",
              "4  [False, False, False, False, False, False, Fal...  \n",
              "5  [True, True, True, True, True, True, True, Fal...  \n",
              "6  [True, False, False, False, False, False, True...  \n",
              "7  [True, False, True, True, True, False, False, ...  \n",
              "8  [True, True, True, False, False, True, False, ...  \n",
              "9  [True, True, True, True, True, True, False, Tr...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51b347cb-25ca-4381-bff4-91046e225e0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>document</th>\n",
              "      <th>full_text</th>\n",
              "      <th>tokens</th>\n",
              "      <th>trailing_whitespace</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>Design Thinking for innovation reflexion-Avril...</td>\n",
              "      <td>[Design, Thinking, for, innovation, reflexion,...</td>\n",
              "      <td>[True, True, True, True, False, False, True, F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10</td>\n",
              "      <td>Diego Estrada\\n\\nDesign Thinking Assignment\\n\\...</td>\n",
              "      <td>[Diego, Estrada, \\n\\n, Design, Thinking, Assig...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16</td>\n",
              "      <td>Reporting process\\n\\nby Gilberto Gamboa\\n\\nCha...</td>\n",
              "      <td>[Reporting, process, \\n\\n, by, Gilberto, Gambo...</td>\n",
              "      <td>[True, False, False, True, True, False, False,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>Design Thinking for Innovation\\n\\nSindy Samaca...</td>\n",
              "      <td>[Design, Thinking, for, Innovation, \\n\\n, Sind...</td>\n",
              "      <td>[True, True, True, False, False, True, False, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>56</td>\n",
              "      <td>Assignment:  Visualization Reflection  Submitt...</td>\n",
              "      <td>[Assignment, :,   , Visualization,  , Reflecti...</td>\n",
              "      <td>[False, False, False, False, False, False, Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>86</td>\n",
              "      <td>Cheese Startup - Learning Launch ​by Eladio Am...</td>\n",
              "      <td>[Cheese, Startup, -, Learning, Launch, ​by, El...</td>\n",
              "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>93</td>\n",
              "      <td>Silvia Villalobos\\n\\nChallenge:\\n\\nThere is a ...</td>\n",
              "      <td>[Silvia, Villalobos, \\n\\n, Challenge, :, \\n\\n,...</td>\n",
              "      <td>[True, False, False, False, False, False, True...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>104</td>\n",
              "      <td>Storytelling  The Path to Innovation\\n\\nDr Sak...</td>\n",
              "      <td>[Storytelling,  , The, Path, to, Innovation, \\...</td>\n",
              "      <td>[True, False, True, True, True, False, False, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>112</td>\n",
              "      <td>Reflection – Learning Launch\\n\\nFrancisco Ferr...</td>\n",
              "      <td>[Reflection, –, Learning, Launch, \\n\\n, Franci...</td>\n",
              "      <td>[True, True, True, False, False, True, False, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>123</td>\n",
              "      <td>Gandhi Institute of Technology and Management ...</td>\n",
              "      <td>[Gandhi, Institute, of, Technology, and, Manag...</td>\n",
              "      <td>[True, True, True, True, True, True, False, Tr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51b347cb-25ca-4381-bff4-91046e225e0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-51b347cb-25ca-4381-bff4-91046e225e0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-51b347cb-25ca-4381-bff4-91046e225e0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a4ecb9c1-0838-41bc-a919-c3d83c7c15d9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a4ecb9c1-0838-41bc-a919-c3d83c7c15d9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a4ecb9c1-0838-41bc-a919-c3d83c7c15d9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_0a246fe9-12be-4a81-919d-351ed0f2cbfc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('test_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0a246fe9-12be-4a81-919d-351ed0f2cbfc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('test_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test_data",
              "summary": "{\n  \"name\": \"test_data\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 46,\n        \"min\": 7,\n        \"max\": 123,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          112,\n          10,\n          86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"full_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Reflection \\u2013 Learning Launch\\n\\nFrancisco Ferreira\\n\\nChallenge\\n\\nI take part of a social enterprenuership group in my university. We were in contact\\n\\nwith Cap\\u00e3o das Antas, a rural Community in the suburbs of S\\u00e3o Carlos (SP-Brazil). We had the  intention to criate, with the local producers, a project that wold improve the quality of life in  the neighborhood. For that, in the first two months we begin to listen each farmer of Cap\\u00e3o  and try identify the principal issues of the place and their residentes. After some visits we  concluded that the principal problem was selling the products that they plant in the local  farms. Therefore, we had the objective to make and test a business model that would increase  their rent.\\n\\nSelection\\n\\nIn order to build a sustainable business model with the farmers, we made a first test\\n\\nwere we delivered the products at the costumer\\u2019s door. The action had a good result but we  want to increase even more ours sales. So we used Learning Launchs to test new ideais and  then improve our business model.\\n\\nApplication\\n\\nAfter we analise all the data we had and build the business model, Its was far from be\\n\\nthe most sustainable and profitable one. To improve our project, we made a plan to test new  ways of seling. So every week, after we analise all the process from the farm to the costumer  door, we propose and teste the improvement in the current business model.\\n\\nIn order to give examples of how it works, after some weeks we notice that the\\n\\nfarmers were having problems in separate the orders. The costumers were ordering with na  app called whatsapp, but the person who was responsable for taking note of the orders was  messy with the conversations feed. As soon as we notice this problem we proposed a new app  that automatically cluster the orders in a simple feed. Therefore we tested this improvement  in the next week and got zero mistakes in separating the orders.\\n\\nInsights\\n\\nThe application of Learning Launches showed me how testing is importante in building\\n\\na solid business model. Therefore, I learned that the more you test possibles ideias, more  chance of sucess you have. Testing a lot of improvement and ideas is not the fastest way to  achieve a better scenario but is cleary a certainly strategy to get there.\\n\\nApproach\\n\\nDuring all the improvement plan that we act every week we propose changes based on\\n\\nwhat we were seeing during the deliveries. I think that we could have achieved better results  by analysis more sources of data, like feedback from all the stakeholders. Besides that we  could have made a better knowledge management of the changes proposed for the business  model.\\n\\n\",\n          \"Diego Estrada\\n\\nDesign Thinking Assignment\\n\\nVisualization Tool\\n\\nChallenge & Selection\\n\\nThe elderly were having a hard time adapting to the changes we brought in our bank. As  a result of a poorly implemented linear solution, a more customer centric approach was  needed.\\n\\nAfter learning about design thinking in this course, we decided to apply it to solve this  problem. The visualization tool allowed the team to create a dynamic presentation using  diagrams, figures and drawings on the go that really resonated among the stakeholders.  Previous to this change, none of our solutions seemed to be adequate for them, but the  new implementation created a different type of connection with them that helped them  understand the problem in the way the team and I did.\\n\\nApplication\\n\\nThe process starts in the prep time. The team uses a series of tools and software to  develop a presentation using the surveys gathered during research and the solutions we  created during the process. The use of graphs to quickly show statistics in a fully visual  way, rather than verbally was a game changer.\\n\\nAfter having a presentation prepared, the team hands an activity to the stakeholders,  where the solutions discussed previously appear. Nonetheless, the solutions need more  work to them. After this. The stakeholders are asked to help complete the solutions  while the team and I create diagrams on a blackboard to represent how their  suggestions would impact on this specific problem.\\n\\nThe use of a group activity strengthens the bond between the company and their  investors. It makes them feel like they take part and help solve the problems as well as  show how customer centric the solutions are. Every complaint and suggestion from  customers are read and evaluated using the graph shown in the course (Involving: can  we do it? Can we afford it? \\u2026). The finalization of this activity leaves the team and the  stakeholders on the same page. It allows them to completely understand and feel part  of the solution and also gives them the chance to ask better questions, which eases the  work of the team.\\n\\nInsight & Approach\\n\\nThe use of this method created a new workflow in the Design Team. It increased the  productivity and the success rate as well as the customer/stakeholders satisfaction. The  use of the visualization tool created an engaged group of people who work together to\\n\\nDiego Estrada\\n\\nfind a solution based on their customer satisfaction. This solution is later revised and  tweaked with the help of the stakeholders who are deeply involved in the process.\\n\\nPresentations, graphics, and activities have added a huge increase in satisfaction. As a  company we also learnt that engaging different areas can be difficult because of the  varying levels of understanding, but when paired with the adequate process things just  flow.\\n\\n(This story is fictional and was created for solving the assignment)\\n\\n\",\n          \"Cheese Startup - Learning Launch \\u200bby Eladio Amaya\\n\\nChallenge\\n\\nWe are a small company in Barcelona (Spain) that refines high-quality organic cheeses  from small producers in the Pyrenees. We also trade milk and yogurts from these  producers. We distribute our dairy products mainly to haute cuisine restaurants (60% of  our turnover) and to Delicatesens stores (35% of our turnover), the remaining 5% we  distribute to individuals, mainly family, friends and acquaintances.    Selection\\n\\nI have chosen the \\\"Learning Launch\\\" because it is more adapted to my way of working  and the needs of the company.    Application\\n\\nDue to the coronavirus crisis, all restaurants have closed and Delicatesen store sales  have dropped dramatically. therefore we have had to change our target niche and head  towards private individuals and common stores.    We have carried out a survey both in small stores and among individuals. In the survey  we asked what types of cheese are the most willing to consume, as well as milk and  yogurts, also the type of milk (goat, cow, sheep), the level of curing and the price they  would be willing to pay for our products. We have also proposed sending boxes with  different products on offer, in which the average price is significantly lower.    After the survey and the observations of individuals and small stores, we have focused  our offer on a certain type of product, we have distributed it and analyzed the result not  only with our customers but also with objective sales figures.    Insight\\n\\nThe result has been spectacular, our weekly turnover had fallen to 25% with a loss of  75% (60% of restaurants and 15% of delicatessen stores). The situation was dramatic  but nowadays sales to individuals have risen from 5% to 25% and common food stores  have gone from 0% to 15%.\\n\\nApproach\\n\\nOur situation is not good, but we hope that when the restaurants open and the economy  recovers. We will have a much broader portfolio of clients and a way of working based  on the client and transferred to the producer. Before, we used to transfer products from  small producers to customers. Now the flow has changed.\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"trailing_whitespace\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_json('/content/test.json')\n",
        "\n",
        "# converting pandas datafram to torch dataset\n",
        "def convert_to_testdataset(data):\n",
        "    return Dataset.from_dict({\n",
        "        'full_text' : [t for t in data['full_text']],\n",
        "        'tokens'    : [t for t in data['tokens']]\n",
        "    })\n",
        "\n",
        "test_given = convert_to_testdataset(test_data)"
      ],
      "metadata": {
        "id": "H8KgVkui2Yt6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending both datasets into one giant one\n",
        "test_dataset = DatasetDict({\n",
        "    'test' : test_given\n",
        "})"
      ],
      "metadata": {
        "id": "E7ySULlP6y_b"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# turn labels into tokens and align them\n",
        "# torch tokenizer will count seperators and beginning of sentences as tokens\n",
        "# we want to ignore these when it comes to evaluating the model\n",
        "def tokenize_testdata(row):\n",
        "    tokenized = tokenizer(\n",
        "        row[\"tokens\"],\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "        max_length=CFG.max_len\n",
        "    )\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "piOvUAcT7CRb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mapping previous 2 functions to our dataset\n",
        "tokeized_test_dataset = test_dataset.map(tokenize_testdata, batched=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d9fa80a7e9834d96b60156854f072931",
            "690fb50d85294534875851224e7c1698",
            "5362b56fbb1a4d47b336be0305a91323",
            "735e1a1504de4aff9a3d5af6a37ddb59",
            "cc044dcf181e4a028a8d122501fe5c38",
            "a353ca97357a4e2c82edfd1e62b2a071",
            "0e199978a88d409d8de1c56d66e4c462",
            "27094111485e46ae860870da62da1c9d",
            "f7574ebd2ed14e0091cc2c3e66c73802",
            "0ba5cefa566e45e3a0c7ba3225cf82a5",
            "beb089b7dcdb493c9bf3388d7361ce6e"
          ]
        },
        "id": "5uOAOu_R7hIR",
        "outputId": "cdae7cb7-55cc-470b-e0cb-f5bd9ac044b0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9fa80a7e9834d96b60156854f072931"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_to_pred_dict(dic, i, d, tok, l, ls):\n",
        "    dic['row_id'].append(i)\n",
        "    dic['document'].append(d)\n",
        "    dic['token'].append(tok)\n",
        "    dic['label'].append(l)\n",
        "    dic['tk_string'].append(ls)\n",
        "    return dic"
      ],
      "metadata": {
        "id": "fVwVj8JGBQBs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = {\n",
        "    'row_id': [],\n",
        "    'document': [],\n",
        "    'token': [],\n",
        "    'label': [],\n",
        "    'tk_string' : [],\n",
        "}\n",
        "\n",
        "i = 0\n",
        "for idx, row in test_data.iterrows():\n",
        "    text = row['tokens']\n",
        "    tokenized_text = loaded_tokenizer(\n",
        "        text,\n",
        "        truncation=False,\n",
        "        max_length=None,\n",
        "        is_split_into_words=True\n",
        "    )\n",
        "    token_map = tokenized_text.tokens()\n",
        "    wids = tokenized_text.word_ids()\n",
        "    input_ids = torch.tensor(tokenized_text['input_ids']).to(loaded_model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        log_pred = loaded_model(input_ids.unsqueeze(0)).logits\n",
        "    preds = torch.argmax(log_pred, dim=2)\n",
        "    ptc = [loaded_model.config.id2label[t.item()] for t in preds[0]]\n",
        "    prev_word_id = -1 # num to track duplicates in data\n",
        "    for w, wi in zip(ptc, wids):\n",
        "        if wi is not None and w != 'O':\n",
        "            if wi == prev_word_id:\n",
        "                prev_word_id = wi\n",
        "                continue\n",
        "            pred_df = add_to_pred_dict(pred_df, i, row['document'], wi, w, text[wi])\n",
        "            prev_word_id = wi\n",
        "            i += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4seGO1-bB6NY",
        "outputId": "93b98d90-3faa-42fd-e2d3-c66e615a27ca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 834 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 595 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 792 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 1166 to 1536 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2045 to 2048 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 483 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 247 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 599 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 592 to 1024 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 2154 to 2560 to be a multiple of `config.attention_window`: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample predicted labels on test data"
      ],
      "metadata": {
        "id": "PxwNvvr1JfFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame(pred_df)\n",
        "print(submission_df.shape)\n",
        "submission_df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "KE38VdeGCUfq",
        "outputId": "4271a902-bf10-4414-9385-59e9ff1dca9a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(27, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   row_id  document  token           label tk_string\n",
              "0       0         7      9  B-NAME_STUDENT  Nathalie\n",
              "1       1         7     10  I-NAME_STUDENT     Sylla\n",
              "2       2         7    482  B-NAME_STUDENT  Nathalie\n",
              "3       3         7    483  I-NAME_STUDENT     Sylla\n",
              "4       4         7    741  B-NAME_STUDENT  Nathalie\n",
              "5       5         7    742  I-NAME_STUDENT     Sylla\n",
              "6       6        10      0  B-NAME_STUDENT     Diego\n",
              "7       7        10      1  I-NAME_STUDENT   Estrada\n",
              "8       8        10    464  B-NAME_STUDENT     Diego\n",
              "9       9        10    465  I-NAME_STUDENT   Estrada"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8c2c1a7-85a5-4c9e-9fde-feeb3146aec5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>document</th>\n",
              "      <th>token</th>\n",
              "      <th>label</th>\n",
              "      <th>tk_string</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>9</td>\n",
              "      <td>B-NAME_STUDENT</td>\n",
              "      <td>Nathalie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>I-NAME_STUDENT</td>\n",
              "      <td>Sylla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>482</td>\n",
              "      <td>B-NAME_STUDENT</td>\n",
              "      <td>Nathalie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>483</td>\n",
              "      <td>I-NAME_STUDENT</td>\n",
              "      <td>Sylla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>741</td>\n",
              "      <td>B-NAME_STUDENT</td>\n",
              "      <td>Nathalie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>742</td>\n",
              "      <td>I-NAME_STUDENT</td>\n",
              "      <td>Sylla</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>B-NAME_STUDENT</td>\n",
              "      <td>Diego</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>I-NAME_STUDENT</td>\n",
              "      <td>Estrada</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>10</td>\n",
              "      <td>464</td>\n",
              "      <td>B-NAME_STUDENT</td>\n",
              "      <td>Diego</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>465</td>\n",
              "      <td>I-NAME_STUDENT</td>\n",
              "      <td>Estrada</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8c2c1a7-85a5-4c9e-9fde-feeb3146aec5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8c2c1a7-85a5-4c9e-9fde-feeb3146aec5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8c2c1a7-85a5-4c9e-9fde-feeb3146aec5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13f82bfc-89a6-44c5-87b2-2cd3d5792d0a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13f82bfc-89a6-44c5-87b2-2cd3d5792d0a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13f82bfc-89a6-44c5-87b2-2cd3d5792d0a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "submission_df",
              "summary": "{\n  \"name\": \"submission_df\",\n  \"rows\": 27,\n  \"fields\": [\n    {\n      \"column\": \"row_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 26,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          8,\n          13,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"document\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 45,\n        \"min\": 7,\n        \"max\": 123,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          112,\n          10,\n          86\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"token\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 242,\n        \"min\": 0,\n        \"max\": 742,\n        \"num_unique_values\": 19,\n        \"samples\": [\n          9,\n          742,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"I-NAME_STUDENT\",\n          \"B-NAME_STUDENT\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tk_string\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"Nathalie\",\n          \"Francisco\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets apply the model on the train data"
      ],
      "metadata": {
        "id": "KWFqE3KaJi-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to predict all labels into a dictionary\n",
        "# doing this to keep track of index and label for evaluating\n",
        "def predict_all_labels(model, tokenizer, data):\n",
        "    pred_labs = []\n",
        "    for _, row in data.iterrows():\n",
        "        txt = row['tokens']\n",
        "        tokenized_text = loaded_tokenizer(\n",
        "            txt,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            is_split_into_words=True\n",
        "        )\n",
        "        wids = tokenized_text.word_ids()\n",
        "        input_ids = torch.tensor(tokenized_text['input_ids']).to(loaded_model.device)\n",
        "        with torch.no_grad():\n",
        "            lp = loaded_model(input_ids.unsqueeze(0)).logits\n",
        "        preds = torch.argmax(lp, dim=2)\n",
        "        ptc = [CFG_new.id2label[t.item()] for t in preds[0]]\n",
        "        prev_word_id = -1\n",
        "        curr_pred_lab = {}\n",
        "        for w, wi in zip(ptc, wids):\n",
        "            if wi is not None:\n",
        "                if wi == prev_word_id:\n",
        "                    prev_word_id = wi\n",
        "                    continue\n",
        "                curr_pred_lab[wi] = w\n",
        "        pred_labs.append(curr_pred_lab)\n",
        "    return pred_labs"
      ],
      "metadata": {
        "id": "GmAKOw1ZxCCO"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to make confusion matrix to determine\n",
        "# model performance on the labels\n",
        "def make_confusion_matrix(preds, y_true):\n",
        "    if len(preds) != len(y_true):\n",
        "        raise ValueError(\"Length of two arrays doesnt match\")\n",
        "    ascore, sscore, tot, tot_labs = 0, 0, 0, 0\n",
        "    cm = np.zeros([len(CFG_new.labels), len(CFG_new.labels)], dtype='int')\n",
        "    for i in range(len(preds)):\n",
        "        for idx in range(len(y_true)):\n",
        "            if idx in preds[i].keys():\n",
        "                tot_labs += 1\n",
        "                if preds[i][idx] == y_true[i][idx]:\n",
        "                    sscore += 1\n",
        "                if preds[i][idx] == y_true[i][idx] and y_true[i][idx] != \"O\":\n",
        "                    ascore += 1\n",
        "                if y_true[i][idx] != \"O\" or preds[i][idx] != \"O\":\n",
        "                    tot += 1\n",
        "                    cm[CFG_new.label2id[y_true[i][idx]], CFG_new.label2id[preds[i][idx]]] += 1\n",
        "\n",
        "    print(f\"Total labels found:  {tot_labs}\\tNon-O labels: {tot}\")\n",
        "    print(f\"Overall accuracy: {sscore/tot_labs:.4f}\")\n",
        "    print(f\"Non-O accuracy: {ascore/tot:.4f}\")\n",
        "    cm = pd.DataFrame(cm, index=CFG_new.labels, columns=CFG_new.labels)\n",
        "    display(cm)\n",
        "    return cm"
      ],
      "metadata": {
        "id": "V394hDU0x1N4"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pii_data_original = pd.read_json('/content/train.json')"
      ],
      "metadata": {
        "id": "LvnObsNfyp5q"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing on the original unfiltered data\n",
        "labs = predict_all_labels(loaded_model, loaded_tokenizer, pii_data_original)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2neutFBx4xM",
        "outputId": "c1ed549d-e12e-4c9c-ed2c-63cd4a488d5c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Input ids are automatically padded from 200 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 507 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 327 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 499 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 380 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 503 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 365 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 419 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 281 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 383 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 509 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 387 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 504 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 498 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 335 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 418 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 425 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 447 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 388 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 301 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 412 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 458 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 491 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 174 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 219 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 399 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 443 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 505 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 396 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 494 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 323 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 464 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 506 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 500 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 271 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 476 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 192 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 474 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 461 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 264 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 401 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 452 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 460 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 484 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 303 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 427 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 501 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 330 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 426 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 298 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 471 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 354 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 381 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 321 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 450 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 293 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 151 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 407 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 215 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 423 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 454 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 378 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 490 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 475 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 218 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 478 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 320 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 316 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 448 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 314 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 377 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 472 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 442 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 204 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 386 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 291 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 434 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 456 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 502 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 337 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 406 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 489 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 336 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 395 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 197 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 422 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 346 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 288 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 446 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 297 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 438 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 420 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 397 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 390 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 385 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 469 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 392 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 362 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 318 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 486 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 416 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 495 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 421 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 324 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 391 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 415 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 356 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 417 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 414 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 404 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 508 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 363 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 368 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 287 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 436 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 468 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 160 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 310 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 182 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 382 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 449 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 463 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 275 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 305 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 437 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 467 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 429 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 488 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 409 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 351 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 408 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 510 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 405 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 276 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 325 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 373 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 453 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 205 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 322 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 511 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 334 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 355 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 364 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 239 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 480 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 162 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 485 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 242 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 465 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 245 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 300 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 306 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 101 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 329 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 492 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 295 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 400 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 268 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 220 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 180 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 473 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 223 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 224 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 203 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 292 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 286 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 411 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 353 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 350 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 413 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 339 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 308 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 470 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 190 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 359 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 482 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 451 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 309 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 95 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 403 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 431 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 428 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 302 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 440 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 424 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 410 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 462 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 432 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 466 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 196 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 430 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 435 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 227 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 357 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 361 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 496 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 183 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 389 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 124 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 398 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 134 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 342 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 250 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 374 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 207 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 256 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 369 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 240 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 384 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 147 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 279 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 347 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 493 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 188 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 131 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 127 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 439 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 244 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 225 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 126 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 178 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 497 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 352 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 312 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 332 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 370 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 87 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 228 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 273 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 107 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 441 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 487 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 333 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 165 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 344 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 366 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 371 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 201 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 260 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 459 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 150 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 457 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 272 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 455 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 294 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 358 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 343 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 433 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 290 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 199 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 177 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 216 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 313 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 262 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 345 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 393 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 348 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 181 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 283 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 241 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 202 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 315 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 360 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 175 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 169 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 402 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 367 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 274 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 142 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 210 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 161 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 234 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 372 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 307 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 349 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 186 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 140 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 445 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 259 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 128 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 137 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 187 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 110 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 145 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 444 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 477 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 233 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 340 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 171 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 189 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 191 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 232 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 379 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 179 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 231 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 117 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 184 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 222 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 394 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 243 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 270 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 311 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 376 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 153 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 148 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 289 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 97 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 479 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 481 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 257 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 375 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 238 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 229 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 79 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 255 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 304 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 280 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 235 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 277 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 253 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 341 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 269 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 328 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 254 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 299 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 284 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 136 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 209 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 149 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 221 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 296 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 282 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 237 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 104 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 195 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 211 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 338 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 248 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 285 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 331 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 263 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 100 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 249 to 512 to be a multiple of `config.attention_window`: 512\n",
            "Input ids are automatically padded from 252 to 512 to be a multiple of `config.attention_window`: 512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = make_confusion_matrix(labs, pii_data_original['labels'].values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "aAiOKlBSx78j",
        "outputId": "1634a2f2-adf3-447c-915e-d2371e5249b5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total labels found:  3067076\tNon-O labels: 2235\n",
            "Overall accuracy: 0.9999\n",
            "Non-O accuracy: 0.8855\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                   O  B-NAME_STUDENT  I-NAME_STUDENT  B-EMAIL  I-EMAIL  \\\n",
              "O                  0             135              67        0        0   \n",
              "B-NAME_STUDENT    20             972               2        0        0   \n",
              "I-NAME_STUDENT     6               0             834        0        0   \n",
              "B-EMAIL            1               0               0       30        0   \n",
              "I-EMAIL            0               0               0        0        0   \n",
              "B-USERNAME         0               0               0        0        0   \n",
              "I-USERNAME         0               0               0        0        0   \n",
              "B-ID_NUM           2               0               0        0        0   \n",
              "I-ID_NUM           0               0               0        0        0   \n",
              "B-PHONE_NUM        0               0               0        0        0   \n",
              "I-PHONE_NUM        1               0               0        0        0   \n",
              "B-URL_PERSONAL     9               0               0        0        0   \n",
              "I-URL_PERSONAL     1               0               0        0        0   \n",
              "B-STREET_ADDRESS   0               0               0        0        0   \n",
              "I-STREET_ADDRESS   0               0               0        0        0   \n",
              "\n",
              "                  B-USERNAME  I-USERNAME  B-ID_NUM  I-ID_NUM  B-PHONE_NUM  \\\n",
              "O                          0           0         0         0            0   \n",
              "B-NAME_STUDENT             0           0         0         0            0   \n",
              "I-NAME_STUDENT             0           0         0         0            0   \n",
              "B-EMAIL                    0           0         0         0            0   \n",
              "I-EMAIL                    0           0         0         0            0   \n",
              "B-USERNAME                 4           0         0         0            0   \n",
              "I-USERNAME                 0           0         0         0            0   \n",
              "B-ID_NUM                   0           0        59         1            0   \n",
              "I-ID_NUM                   0           0         0         1            0   \n",
              "B-PHONE_NUM                0           0         0         0            5   \n",
              "I-PHONE_NUM                0           0         0         0            0   \n",
              "B-URL_PERSONAL             0           0         0         0            0   \n",
              "I-URL_PERSONAL             0           0         0         0            0   \n",
              "B-STREET_ADDRESS           0           0         0         0            0   \n",
              "I-STREET_ADDRESS           0           0         0         0            0   \n",
              "\n",
              "                  I-PHONE_NUM  B-URL_PERSONAL  I-URL_PERSONAL  \\\n",
              "O                           0              11               0   \n",
              "B-NAME_STUDENT              0               0               0   \n",
              "I-NAME_STUDENT              0               0               0   \n",
              "B-EMAIL                     0               0               0   \n",
              "I-EMAIL                     0               0               0   \n",
              "B-USERNAME                  0               0               0   \n",
              "I-USERNAME                  0               0               0   \n",
              "B-ID_NUM                    0               0               0   \n",
              "I-ID_NUM                    0               0               0   \n",
              "B-PHONE_NUM                 0               0               0   \n",
              "I-PHONE_NUM                 9               0               0   \n",
              "B-URL_PERSONAL              0              43               0   \n",
              "I-URL_PERSONAL              0               0               0   \n",
              "B-STREET_ADDRESS            0               0               0   \n",
              "I-STREET_ADDRESS            0               0               0   \n",
              "\n",
              "                  B-STREET_ADDRESS  I-STREET_ADDRESS  \n",
              "O                                0                 0  \n",
              "B-NAME_STUDENT                   0                 0  \n",
              "I-NAME_STUDENT                   0                 0  \n",
              "B-EMAIL                          0                 0  \n",
              "I-EMAIL                          0                 0  \n",
              "B-USERNAME                       0                 0  \n",
              "I-USERNAME                       0                 0  \n",
              "B-ID_NUM                         0                 0  \n",
              "I-ID_NUM                         0                 0  \n",
              "B-PHONE_NUM                      0                 0  \n",
              "I-PHONE_NUM                      0                 0  \n",
              "B-URL_PERSONAL                   0                 0  \n",
              "I-URL_PERSONAL                   0                 0  \n",
              "B-STREET_ADDRESS                 2                 0  \n",
              "I-STREET_ADDRESS                 0                20  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9e268a5-60f4-46a4-af10-74f72a1199bc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>O</th>\n",
              "      <th>B-NAME_STUDENT</th>\n",
              "      <th>I-NAME_STUDENT</th>\n",
              "      <th>B-EMAIL</th>\n",
              "      <th>I-EMAIL</th>\n",
              "      <th>B-USERNAME</th>\n",
              "      <th>I-USERNAME</th>\n",
              "      <th>B-ID_NUM</th>\n",
              "      <th>I-ID_NUM</th>\n",
              "      <th>B-PHONE_NUM</th>\n",
              "      <th>I-PHONE_NUM</th>\n",
              "      <th>B-URL_PERSONAL</th>\n",
              "      <th>I-URL_PERSONAL</th>\n",
              "      <th>B-STREET_ADDRESS</th>\n",
              "      <th>I-STREET_ADDRESS</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>O</th>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-NAME_STUDENT</th>\n",
              "      <td>20</td>\n",
              "      <td>972</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-NAME_STUDENT</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>834</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-EMAIL</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-EMAIL</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-USERNAME</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-USERNAME</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-ID_NUM</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>59</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-ID_NUM</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-PHONE_NUM</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-PHONE_NUM</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-URL_PERSONAL</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>43</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-URL_PERSONAL</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B-STREET_ADDRESS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>I-STREET_ADDRESS</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9e268a5-60f4-46a4-af10-74f72a1199bc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9e268a5-60f4-46a4-af10-74f72a1199bc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9e268a5-60f4-46a4-af10-74f72a1199bc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8789bf2-5b12-479d-af29-602d9d159763\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8789bf2-5b12-479d-af29-602d9d159763')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8789bf2-5b12-479d-af29-602d9d159763 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"cm = make_confusion_matrix(labs, pii_data_original['labels']\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"O\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0,\n          20,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-NAME_STUDENT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 250,\n        \"min\": 0,\n        \"max\": 972,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          135,\n          972,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-NAME_STUDENT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 214,\n        \"min\": 0,\n        \"max\": 834,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2,\n          0,\n          67\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-EMAIL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7,\n        \"min\": 0,\n        \"max\": 30,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          30,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-EMAIL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-USERNAME\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-USERNAME\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-ID_NUM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 59,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          59\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-ID_NUM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-PHONE_NUM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 5,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-PHONE_NUM\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 9,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-URL_PERSONAL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 0,\n        \"max\": 43,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          11\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-URL_PERSONAL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"B-STREET_ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I-STREET_ADDRESS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5,\n        \"min\": 0,\n        \"max\": 20,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          20\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    }
  ]
}